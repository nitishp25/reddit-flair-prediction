{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX0YtJEL9OCZ",
        "colab_type": "code",
        "outputId": "74bab959-ceed-4bca-f896-0f0e1318bd45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!pip install pymongo\n",
        "\n",
        "import logging\n",
        "import json\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from numpy import random\n",
        "import gensim\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (3.9.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHVoh1KI8Nm2",
        "colab_type": "text"
      },
      "source": [
        "## Getting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxPVFxLX9WXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "client = MongoClient('mongodb://nitish:umeshpapa123@cluster0-shard-00-00-ifnda.mongodb.net:27017,cluster0-shard-00-01-ifnda.mongodb.net:27017,cluster0-shard-00-02-ifnda.mongodb.net:27017/test?ssl=true&replicaSet=Cluster0-shard-0&authSource=admin&retryWrites=true&w=majority')\n",
        "db = client.database\n",
        "collection = db.data_collection\n",
        "posts = db.posts\n",
        "data = posts.find_one()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLQa4xvs-OK3",
        "colab_type": "code",
        "outputId": "e7d772fa-0e79-465d-b721-2dce8a62e491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "data = pd.DataFrame(data)\n",
        "plt.figure(figsize=(10,4))\n",
        "data.flair.value_counts().plot(kind='bar');\n",
        "flairs = [\"AskIndia\", \"Non-Political\", \"Reddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\", \"AMA\"]\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAFVCAYAAAA35UGiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkgRsdxq-SY_",
        "colab_type": "code",
        "outputId": "56908e33-c971-47d5-a38d-cb3a3e688d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "source": [
        "data = data.drop(columns=\"_id\")\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flair</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>score</th>\n",
              "      <th>url</th>\n",
              "      <th>num_comm</th>\n",
              "      <th>created</th>\n",
              "      <th>id</th>\n",
              "      <th>author</th>\n",
              "      <th>comm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>Need feedback for Insurance Policy that I took...</td>\n",
              "      <td>**Re-posting here because of lack of activity ...</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/1s57oi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.386254e+09</td>\n",
              "      <td>1s57oi</td>\n",
              "      <td>dhavalcoholic</td>\n",
              "      <td>Dear Policy Holder(Dhavalcoholic),\\n \\nWe req...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>Somebody want to kill my full family what to do?</td>\n",
              "      <td>It's now 24hrs, But local police station is no...</td>\n",
              "      <td>92</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/b7pvwt...</td>\n",
              "      <td>24</td>\n",
              "      <td>1.554080e+09</td>\n",
              "      <td>b7pvwt</td>\n",
              "      <td>amitkumarthakur</td>\n",
              "      <td>Calm down.\\nGo to the SP office of your town,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>Ambassador of India takes back my newly issued...</td>\n",
              "      <td>Hello /AskIndia!  First time poster, long time...</td>\n",
              "      <td>13</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/bdfid1...</td>\n",
              "      <td>27</td>\n",
              "      <td>1.555361e+09</td>\n",
              "      <td>bdfid1</td>\n",
              "      <td>FrustratedOCIHopeful</td>\n",
              "      <td>Honestly, she and her supervisor behaved *exa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>Randians, what are you too afraid to ask?</td>\n",
              "      <td>r/TooAfraidToAsk India edition</td>\n",
              "      <td>16</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/cu1xn4...</td>\n",
              "      <td>22</td>\n",
              "      <td>1.566529e+09</td>\n",
              "      <td>cu1xn4</td>\n",
              "      <td>aloo_vs_bhaloo</td>\n",
              "      <td>How does Modi control his sex desires? Or if ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>[AskIndia] Cingari, Cengar or Tzengar?</td>\n",
              "      <td>Hello,\\n\\nI submitted this to /r/rAskIndia a w...</td>\n",
              "      <td>0</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/18ntue...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.361085e+09</td>\n",
              "      <td>18ntue</td>\n",
              "      <td>multubunu</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      flair  ...                                               comm\n",
              "0  AskIndia  ...   Dear Policy Holder(Dhavalcoholic),\\n \\nWe req...\n",
              "1  AskIndia  ...   Calm down.\\nGo to the SP office of your town,...\n",
              "2  AskIndia  ...   Honestly, she and her supervisor behaved *exa...\n",
              "3  AskIndia  ...   How does Modi control his sex desires? Or if ...\n",
              "4  AskIndia  ...                                                   \n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5klpYDR7gqC",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-QfbU0y7jlP",
        "colab_type": "code",
        "outputId": "e360514e-86d5-4bf9-e437-f0f1b64b1491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    return text\n",
        "  \n",
        "def todate(created):\n",
        "    return dt.datetime.fromtimestamp(created)\n",
        "  \n",
        "try:\n",
        "  created = data[\"created\"].apply(todate)\n",
        "  data = data.assign(created = created)\n",
        "except:\n",
        "  print(\"already timestamp\")\n",
        "\n",
        "def tostr(value):\n",
        "    return str(value)\n",
        "  \n",
        "data['title'] = data['title'].apply(tostr)\n",
        "data['title'] = data['title'].apply(clean_text)\n",
        "data['body'] = data['body'].apply(tostr)\n",
        "data['body'] = data['body'].apply(clean_text)\n",
        "data['comm'] = data['comm'].apply(tostr)\n",
        "data['comm'] = data['comm'].apply(clean_text)\n",
        "data['url'] = data['url'].apply(tostr)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://youtu.be/kBvIqVr__C0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n30eEh41Gb8y",
        "colab_type": "code",
        "outputId": "65af26ba-18b6-4681-ff67-6c6a1d393812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "source": [
        "data.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flair</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>score</th>\n",
              "      <th>url</th>\n",
              "      <th>num_comm</th>\n",
              "      <th>created</th>\n",
              "      <th>id</th>\n",
              "      <th>author</th>\n",
              "      <th>comm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2296</th>\n",
              "      <td>AMA</td>\n",
              "      <td>r india met spent time celebrity actors anyone...</td>\n",
              "      <td></td>\n",
              "      <td>33</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/1u5caw...</td>\n",
              "      <td>168</td>\n",
              "      <td>2014-01-01 15:40:35</td>\n",
              "      <td>1u5caw</td>\n",
              "      <td>varuval</td>\n",
              "      <td>true storyi peed standing next ratan tata los ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2297</th>\n",
              "      <td>AMA</td>\n",
              "      <td>upcoming ama rocky mayur monday 4th august 120...</td>\n",
              "      <td>rocky singh mayur sharma childhood friends tog...</td>\n",
              "      <td>83</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/2cesw5...</td>\n",
              "      <td>59</td>\n",
              "      <td>2014-08-02 16:28:37</td>\n",
              "      <td>2cesw5</td>\n",
              "      <td>rahulthewall</td>\n",
              "      <td>welcome guys http wwwredditcom r india comment...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2298</th>\n",
              "      <td>AMA</td>\n",
              "      <td>friend completed cycling 6200 kms kashmir kany...</td>\n",
              "      <td></td>\n",
              "      <td>455</td>\n",
              "      <td>http://imgur.com/fv9DA</td>\n",
              "      <td>62</td>\n",
              "      <td>2013-01-06 20:38:16</td>\n",
              "      <td>1624gc</td>\n",
              "      <td>petty86</td>\n",
              "      <td>great achievement indeed convince ama listed e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2299</th>\n",
              "      <td>AMA</td>\n",
              "      <td>priyanka chopras reaction ama</td>\n",
              "      <td></td>\n",
              "      <td>94</td>\n",
              "      <td>http://gfycat.com/InsistentFlamboyantInganue</td>\n",
              "      <td>59</td>\n",
              "      <td>2014-07-03 04:39:38</td>\n",
              "      <td>29ojfi</td>\n",
              "      <td>DesiGif</td>\n",
              "      <td>one new profiles pr team created asked last ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2300</th>\n",
              "      <td>AMA</td>\n",
              "      <td>hey reddit im anoop bhat draw stuff pen ink ba...</td>\n",
              "      <td>hi im anoop architect freelance illustrator ba...</td>\n",
              "      <td>147</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/84lr68...</td>\n",
              "      <td>103</td>\n",
              "      <td>2018-03-15 19:32:47</td>\n",
              "      <td>84lr68</td>\n",
              "      <td>scourgwreck</td>\n",
              "      <td>hi anoopdo sell posters online ship outside in...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     flair  ...                                               comm\n",
              "2296   AMA  ...  true storyi peed standing next ratan tata los ...\n",
              "2297   AMA  ...  welcome guys http wwwredditcom r india comment...\n",
              "2298   AMA  ...  great achievement indeed convince ama listed e...\n",
              "2299   AMA  ...  one new profiles pr team created asked last ti...\n",
              "2300   AMA  ...  hi anoopdo sell posters online ship outside in...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SosgjCUCOP0a",
        "colab_type": "text"
      },
      "source": [
        "## 1. Feature #1 : Title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy0VsCtWQRAX",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl51oLlCOSbi",
        "colab_type": "code",
        "outputId": "99309de4-62e9-4735-f9d3-061e41c48124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Only taking title, body, url, comments as features as they have the most\n",
        "# significant amount of natural language related to the flair\n",
        "\n",
        "X = data[['title', 'body', 'url', 'comm']]\n",
        "y = data['flair']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "\n",
        "X1_train = X_train['title']\n",
        "X1_test = X_test['title']\n",
        "\n",
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "nb.fit(X1_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6268980477223427\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.61      0.65      0.63        34\n",
            "     Non-Political       0.53      0.85      0.65        39\n",
            "       Reddiquette       0.59      0.39      0.47        41\n",
            "         Scheduled       0.69      0.75      0.72        36\n",
            "       Photography       0.77      0.95      0.85        38\n",
            "Science/Technology       0.51      0.75      0.61        32\n",
            "          Politics       0.53      0.58      0.56        43\n",
            "  Business/Finance       0.59      0.45      0.51        44\n",
            "    Policy/Economy       1.00      0.16      0.28        31\n",
            "            Sports       0.68      0.60      0.64        43\n",
            "              Food       0.58      0.60      0.59        35\n",
            "               AMA       0.79      0.76      0.77        45\n",
            "\n",
            "          accuracy                           0.63       461\n",
            "         macro avg       0.66      0.62      0.61       461\n",
            "      weighted avg       0.65      0.63      0.61       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uRe9Im9QXGp",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 SGD/LinearSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqg2PSjaPA6C",
        "colab_type": "code",
        "outputId": "01274d44-5e64-4e97-cd68-9bb63f9fe895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
        "               ])\n",
        "sgd.fit(X1_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = sgd.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6919739696312365\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.65      0.71      0.68        34\n",
            "     Non-Political       0.78      0.90      0.83        39\n",
            "       Reddiquette       0.59      0.41      0.49        41\n",
            "         Scheduled       0.68      0.78      0.73        36\n",
            "       Photography       0.84      1.00      0.92        38\n",
            "Science/Technology       0.75      0.75      0.75        32\n",
            "          Politics       0.53      0.53      0.53        43\n",
            "  Business/Finance       0.65      0.50      0.56        44\n",
            "    Policy/Economy       0.76      0.61      0.68        31\n",
            "            Sports       0.70      0.72      0.71        43\n",
            "              Food       0.61      0.57      0.59        35\n",
            "               AMA       0.72      0.84      0.78        45\n",
            "\n",
            "          accuracy                           0.69       461\n",
            "         macro avg       0.69      0.69      0.69       461\n",
            "      weighted avg       0.69      0.69      0.68       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqOzt5g3Q156",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u5sQRStQmhA",
        "colab_type": "code",
        "outputId": "c02d1d01-af3e-45d8-8754-538c07b380bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
        "               ])\n",
        "logreg.fit(X1_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6963123644251626\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.70      0.76      0.73        34\n",
            "     Non-Political       0.83      0.90      0.86        39\n",
            "       Reddiquette       0.56      0.46      0.51        41\n",
            "         Scheduled       0.70      0.78      0.74        36\n",
            "       Photography       0.93      0.97      0.95        38\n",
            "Science/Technology       0.70      0.72      0.71        32\n",
            "          Politics       0.62      0.60      0.61        43\n",
            "  Business/Finance       0.59      0.45      0.51        44\n",
            "    Policy/Economy       0.87      0.65      0.74        31\n",
            "            Sports       0.66      0.67      0.67        43\n",
            "              Food       0.62      0.57      0.60        35\n",
            "               AMA       0.63      0.84      0.72        45\n",
            "\n",
            "          accuracy                           0.70       461\n",
            "         macro avg       0.70      0.70      0.70       461\n",
            "      weighted avg       0.69      0.70      0.69       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkrWHgCDSjWj",
        "colab_type": "text"
      },
      "source": [
        "### 1.4 AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-7GjUNwSlyA",
        "colab_type": "code",
        "outputId": "33a8d9a0-c82d-4a11-d138-e2a544c95fda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', AdaBoostClassifier(n_estimators = 500, learning_rate=0.9)),\n",
        "               ])\n",
        "ada.fit(X1_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.4078091106290672\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.95      0.56      0.70        34\n",
            "     Non-Political       0.92      0.87      0.89        39\n",
            "       Reddiquette       0.13      0.93      0.23        41\n",
            "         Scheduled       0.88      0.58      0.70        36\n",
            "       Photography       1.00      0.03      0.05        38\n",
            "Science/Technology       1.00      0.56      0.72        32\n",
            "          Politics       0.00      0.00      0.00        43\n",
            "  Business/Finance       0.00      0.00      0.00        44\n",
            "    Policy/Economy       0.86      0.58      0.69        31\n",
            "            Sports       1.00      0.40      0.57        43\n",
            "              Food       0.90      0.26      0.40        35\n",
            "               AMA       0.93      0.29      0.44        45\n",
            "\n",
            "          accuracy                           0.41       461\n",
            "         macro avg       0.71      0.42      0.45       461\n",
            "      weighted avg       0.69      0.41      0.43       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2hBfrV2WF9b",
        "colab_type": "text"
      },
      "source": [
        "### 1.5 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax_-PNk1WH9_",
        "colab_type": "code",
        "outputId": "d0d8d217-1b1c-4f7c-9de9-c76495ed7d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "  \n",
        "ranfor = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', RandomForestClassifier(n_estimators = 500, random_state = 42)),\n",
        "                 ])\n",
        "ranfor.fit(X1_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6550976138828634\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.64      0.62      0.63        34\n",
            "     Non-Political       0.88      0.90      0.89        39\n",
            "       Reddiquette       0.47      0.51      0.49        41\n",
            "         Scheduled       0.71      0.81      0.75        36\n",
            "       Photography       0.93      0.97      0.95        38\n",
            "Science/Technology       0.65      0.69      0.67        32\n",
            "          Politics       0.45      0.56      0.50        43\n",
            "  Business/Finance       0.54      0.45      0.49        44\n",
            "    Policy/Economy       0.95      0.58      0.72        31\n",
            "            Sports       0.74      0.53      0.62        43\n",
            "              Food       0.43      0.51      0.47        35\n",
            "               AMA       0.74      0.76      0.75        45\n",
            "\n",
            "          accuracy                           0.66       461\n",
            "         macro avg       0.68      0.66      0.66       461\n",
            "      weighted avg       0.67      0.66      0.66       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18Lqp9jGX_BB",
        "colab_type": "text"
      },
      "source": [
        "### 1.6 MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plePunVAYDrf",
        "colab_type": "code",
        "outputId": "83d0c342-6ed5-4cba-f16d-9f8da07d9f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "  \n",
        "mlp = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', MLPClassifier(hidden_layer_sizes=(35,35,35), alpha=0.1, random_state=42, max_iter=200)),\n",
        "                 ])\n",
        "  \n",
        "mlp.fit(X1_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6507592190889371\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.55      0.71      0.62        34\n",
            "     Non-Political       0.81      0.87      0.84        39\n",
            "       Reddiquette       0.54      0.37      0.43        41\n",
            "         Scheduled       0.71      0.67      0.69        36\n",
            "       Photography       0.92      0.95      0.94        38\n",
            "Science/Technology       0.74      0.72      0.73        32\n",
            "          Politics       0.40      0.67      0.50        43\n",
            "  Business/Finance       0.42      0.50      0.46        44\n",
            "    Policy/Economy       0.93      0.45      0.61        31\n",
            "            Sports       0.83      0.67      0.74        43\n",
            "              Food       0.63      0.49      0.55        35\n",
            "               AMA       0.80      0.73      0.77        45\n",
            "\n",
            "          accuracy                           0.65       461\n",
            "         macro avg       0.69      0.65      0.66       461\n",
            "      weighted avg       0.68      0.65      0.65       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmEecWPMcXlo",
        "colab_type": "text"
      },
      "source": [
        "## 2. Feature #2 : Body"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBdw0kFNchE5",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxP91vMHagKQ",
        "colab_type": "code",
        "outputId": "407854e9-fb63-407a-e186-b661ea7d5014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "X2_train = X_train['body']\n",
        "X2_test = X_test['body']\n",
        "\n",
        "nb.fit(X2_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.23644251626898047\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.67      0.29      0.41        34\n",
            "     Non-Political       0.34      0.54      0.42        39\n",
            "       Reddiquette       0.23      0.68      0.34        41\n",
            "         Scheduled       0.33      0.03      0.05        36\n",
            "       Photography       0.00      0.00      0.00        38\n",
            "Science/Technology       0.12      0.84      0.21        32\n",
            "          Politics       1.00      0.02      0.05        43\n",
            "  Business/Finance       0.00      0.00      0.00        44\n",
            "    Policy/Economy       1.00      0.16      0.28        31\n",
            "            Sports       0.50      0.07      0.12        43\n",
            "              Food       0.71      0.29      0.41        35\n",
            "               AMA       0.60      0.07      0.12        45\n",
            "\n",
            "          accuracy                           0.24       461\n",
            "         macro avg       0.46      0.25      0.20       461\n",
            "      weighted avg       0.45      0.24      0.19       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5pah0AT8Xzq",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 SGD/LinearSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwlavI2k8OHB",
        "colab_type": "code",
        "outputId": "565b07f3-1b6e-46e0-facb-24dac5f2668b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "sgd.fit(X2_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = sgd.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.3665943600867679\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.60      0.44      0.51        34\n",
            "     Non-Political       0.45      0.46      0.46        39\n",
            "       Reddiquette       0.49      0.56      0.52        41\n",
            "         Scheduled       0.41      0.19      0.26        36\n",
            "       Photography       0.25      0.03      0.05        38\n",
            "Science/Technology       0.47      0.28      0.35        32\n",
            "          Politics       0.50      0.14      0.22        43\n",
            "  Business/Finance       0.17      0.82      0.28        44\n",
            "    Policy/Economy       0.79      0.61      0.69        31\n",
            "            Sports       0.55      0.14      0.22        43\n",
            "              Food       0.55      0.46      0.50        35\n",
            "               AMA       0.72      0.29      0.41        45\n",
            "\n",
            "          accuracy                           0.37       461\n",
            "         macro avg       0.50      0.37      0.37       461\n",
            "      weighted avg       0.49      0.37      0.36       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ck3492B9VaC",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndnqdtaz9Fq3",
        "colab_type": "code",
        "outputId": "699c41c9-eca7-4ac7-ae85-020ed51ba665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "logreg.fit(X2_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.3362255965292842\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.52      0.41      0.46        34\n",
            "     Non-Political       0.37      0.49      0.42        39\n",
            "       Reddiquette       0.58      0.51      0.55        41\n",
            "         Scheduled       0.50      0.19      0.28        36\n",
            "       Photography       0.08      0.03      0.04        38\n",
            "Science/Technology       0.45      0.28      0.35        32\n",
            "          Politics       0.38      0.12      0.18        43\n",
            "  Business/Finance       0.16      0.82      0.27        44\n",
            "    Policy/Economy       0.84      0.52      0.64        31\n",
            "            Sports       0.60      0.14      0.23        43\n",
            "              Food       0.47      0.40      0.43        35\n",
            "               AMA       0.70      0.16      0.25        45\n",
            "\n",
            "          accuracy                           0.34       461\n",
            "         macro avg       0.47      0.34      0.34       461\n",
            "      weighted avg       0.47      0.34      0.33       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1p8DH1n9oFy",
        "colab_type": "text"
      },
      "source": [
        "### 2.4 AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfauWsRe9tBM",
        "colab_type": "code",
        "outputId": "38bb0c84-8bd5-420b-d47e-1d24d5a46bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "ada.fit(X2_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.23644251626898047\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.27      0.24      0.25        34\n",
            "     Non-Political       0.21      0.44      0.28        39\n",
            "       Reddiquette       0.65      0.27      0.38        41\n",
            "         Scheduled       0.30      0.08      0.13        36\n",
            "       Photography       0.09      0.08      0.09        38\n",
            "Science/Technology       0.46      0.19      0.27        32\n",
            "          Politics       0.33      0.12      0.17        43\n",
            "  Business/Finance       0.16      0.82      0.27        44\n",
            "    Policy/Economy       0.71      0.16      0.26        31\n",
            "            Sports       0.56      0.12      0.19        43\n",
            "              Food       0.30      0.09      0.13        35\n",
            "               AMA       0.44      0.16      0.23        45\n",
            "\n",
            "          accuracy                           0.24       461\n",
            "         macro avg       0.37      0.23      0.22       461\n",
            "      weighted avg       0.37      0.24      0.22       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzsBh189-NG_",
        "colab_type": "text"
      },
      "source": [
        "### 2.5 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9RXz2Oz95O6",
        "colab_type": "code",
        "outputId": "d6842197-44e4-4d21-bfa6-935600f0c3a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "ranfor.fit(X2_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.3644251626898048\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.56      0.41      0.47        34\n",
            "     Non-Political       0.35      0.72      0.47        39\n",
            "       Reddiquette       0.64      0.61      0.62        41\n",
            "         Scheduled       0.45      0.14      0.21        36\n",
            "       Photography       0.00      0.00      0.00        38\n",
            "Science/Technology       0.75      0.28      0.41        32\n",
            "          Politics       0.60      0.21      0.31        43\n",
            "  Business/Finance       0.16      0.80      0.27        44\n",
            "    Policy/Economy       1.00      0.52      0.68        31\n",
            "            Sports       0.50      0.07      0.12        43\n",
            "              Food       0.80      0.46      0.58        35\n",
            "               AMA       0.53      0.18      0.27        45\n",
            "\n",
            "          accuracy                           0.36       461\n",
            "         macro avg       0.53      0.37      0.37       461\n",
            "      weighted avg       0.51      0.36      0.36       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zh_y9Rm-ewa",
        "colab_type": "text"
      },
      "source": [
        "### 2.6 MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xhYXP1E-WM0",
        "colab_type": "code",
        "outputId": "8696db3e-45e1-4388-8756-b9d0386cbfee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "mlp.fit(X2_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.2950108459869848\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.40      0.24      0.30        34\n",
            "     Non-Political       0.41      0.28      0.33        39\n",
            "       Reddiquette       0.61      0.46      0.53        41\n",
            "         Scheduled       0.44      0.19      0.27        36\n",
            "       Photography       0.08      0.03      0.04        38\n",
            "Science/Technology       0.39      0.28      0.33        32\n",
            "          Politics       0.26      0.14      0.18        43\n",
            "  Business/Finance       0.16      0.84      0.27        44\n",
            "    Policy/Economy       0.80      0.39      0.52        31\n",
            "            Sports       0.43      0.07      0.12        43\n",
            "              Food       0.42      0.43      0.42        35\n",
            "               AMA       0.53      0.18      0.27        45\n",
            "\n",
            "          accuracy                           0.30       461\n",
            "         macro avg       0.41      0.29      0.30       461\n",
            "      weighted avg       0.40      0.30      0.29       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3erY2S1Y-ygW",
        "colab_type": "text"
      },
      "source": [
        "## 3. Feature #3 : Url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hHfBCkK_VNE",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knVuhJuC-rX6",
        "colab_type": "code",
        "outputId": "460ab8ba-5f24-48e9-8f86-8fb27b486084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "X3_train = X_train['url']\n",
        "X3_test = X_test['url']\n",
        "\n",
        "nb.fit(X3_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.27765726681127983\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.20      0.03      0.05        34\n",
            "     Non-Political       0.15      0.92      0.26        39\n",
            "       Reddiquette       0.43      0.07      0.12        41\n",
            "         Scheduled       0.38      0.33      0.35        36\n",
            "       Photography       0.33      0.18      0.24        38\n",
            "Science/Technology       0.46      0.19      0.27        32\n",
            "          Politics       0.57      0.37      0.45        43\n",
            "  Business/Finance       0.46      0.41      0.43        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.36      0.37      0.36        43\n",
            "              Food       0.39      0.20      0.26        35\n",
            "               AMA       0.60      0.13      0.22        45\n",
            "\n",
            "          accuracy                           0.28       461\n",
            "         macro avg       0.36      0.27      0.25       461\n",
            "      weighted avg       0.37      0.28      0.26       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_IJImFdAoqD",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 SGD/LinearSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6pGgYU4_a4z",
        "colab_type": "code",
        "outputId": "f75b7e43-a4fb-498e-8ad0-a5373194f287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "sgd.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = sgd.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.29718004338394793\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.17      0.03      0.05        34\n",
            "     Non-Political       0.15      0.92      0.26        39\n",
            "       Reddiquette       0.44      0.10      0.16        41\n",
            "         Scheduled       0.60      0.17      0.26        36\n",
            "       Photography       0.29      0.18      0.23        38\n",
            "Science/Technology       0.62      0.16      0.25        32\n",
            "          Politics       0.58      0.42      0.49        43\n",
            "  Business/Finance       0.45      0.45      0.45        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.55      0.37      0.44        43\n",
            "              Food       0.43      0.26      0.32        35\n",
            "               AMA       0.39      0.33      0.36        45\n",
            "\n",
            "          accuracy                           0.30       461\n",
            "         macro avg       0.39      0.28      0.27       461\n",
            "      weighted avg       0.40      0.30      0.29       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzyeSRNNA0CL",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfDLbb_yAyVx",
        "colab_type": "code",
        "outputId": "30d37fc9-4c63-4d68-a986-3870a433457f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "logreg.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.28633405639913234\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.25      0.03      0.05        34\n",
            "     Non-Political       0.15      0.92      0.26        39\n",
            "       Reddiquette       0.33      0.07      0.12        41\n",
            "         Scheduled       0.50      0.17      0.25        36\n",
            "       Photography       0.29      0.18      0.23        38\n",
            "Science/Technology       0.60      0.19      0.29        32\n",
            "          Politics       0.53      0.40      0.45        43\n",
            "  Business/Finance       0.46      0.39      0.42        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.43      0.37      0.40        43\n",
            "              Food       0.50      0.26      0.34        35\n",
            "               AMA       0.38      0.31      0.34        45\n",
            "\n",
            "          accuracy                           0.29       461\n",
            "         macro avg       0.37      0.27      0.26       461\n",
            "      weighted avg       0.37      0.29      0.27       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAjzohG0Bjes",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-NdBJwGBAg3",
        "colab_type": "code",
        "outputId": "1d7e4833-5b6f-4446-9a2c-b868826c70a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "ada.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.22559652928416485\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        34\n",
            "     Non-Political       0.15      0.97      0.25        39\n",
            "       Reddiquette       0.50      0.05      0.09        41\n",
            "         Scheduled       0.33      0.14      0.20        36\n",
            "       Photography       0.33      0.11      0.16        38\n",
            "Science/Technology       0.38      0.16      0.22        32\n",
            "          Politics       0.31      0.37      0.34        43\n",
            "  Business/Finance       0.30      0.52      0.38        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.25      0.05      0.08        43\n",
            "              Food       0.67      0.11      0.20        35\n",
            "               AMA       0.45      0.11      0.18        45\n",
            "\n",
            "          accuracy                           0.23       461\n",
            "         macro avg       0.31      0.22      0.17       461\n",
            "      weighted avg       0.31      0.23      0.18       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYN9e6qNBsnI",
        "colab_type": "text"
      },
      "source": [
        "### 3.5 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nG2KWRFBp34",
        "colab_type": "code",
        "outputId": "187d85f1-ba72-4f89-a7f4-8709027d1394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "ranfor.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.26247288503253796\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        34\n",
            "     Non-Political       0.00      0.00      0.00        39\n",
            "       Reddiquette       0.12      0.73      0.20        41\n",
            "         Scheduled       0.83      0.14      0.24        36\n",
            "       Photography       0.40      0.16      0.23        38\n",
            "Science/Technology       0.50      0.22      0.30        32\n",
            "          Politics       0.55      0.40      0.46        43\n",
            "  Business/Finance       0.41      0.52      0.46        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.54      0.30      0.39        43\n",
            "              Food       0.35      0.23      0.28        35\n",
            "               AMA       0.35      0.27      0.30        45\n",
            "\n",
            "          accuracy                           0.26       461\n",
            "         macro avg       0.34      0.25      0.24       461\n",
            "      weighted avg       0.34      0.26      0.25       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9LJgQPdCPgL",
        "colab_type": "text"
      },
      "source": [
        "### 3.6 MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTT2p78QBxzs",
        "colab_type": "code",
        "outputId": "669e7aac-3af2-472e-8721-f6d210c0955f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "mlp.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.23644251626898047\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.20      0.03      0.05        34\n",
            "     Non-Political       1.00      0.03      0.05        39\n",
            "       Reddiquette       0.12      0.71      0.20        41\n",
            "         Scheduled       0.60      0.08      0.15        36\n",
            "       Photography       0.29      0.18      0.23        38\n",
            "Science/Technology       0.24      0.28      0.26        32\n",
            "          Politics       0.43      0.42      0.42        43\n",
            "  Business/Finance       0.37      0.32      0.34        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.42      0.26      0.32        43\n",
            "              Food       0.30      0.17      0.22        35\n",
            "               AMA       0.67      0.22      0.33        45\n",
            "\n",
            "          accuracy                           0.24       461\n",
            "         macro avg       0.39      0.22      0.21       461\n",
            "      weighted avg       0.40      0.24      0.22       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NP9Lw2GDOAc",
        "colab_type": "text"
      },
      "source": [
        "## 4. Feature #4 : Comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVi6tOtmDREO",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQg-kBb7CZUZ",
        "colab_type": "code",
        "outputId": "fdfe3496-7cea-4362-94c7-3cd7f0a82ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "X4_train = X_train['comm']\n",
        "X4_test = X_test['comm']\n",
        "\n",
        "nb.fit(X4_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.4837310195227766\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.23      0.91      0.37        34\n",
            "     Non-Political       0.33      0.28      0.31        39\n",
            "       Reddiquette       0.58      0.34      0.43        41\n",
            "         Scheduled       0.67      0.72      0.69        36\n",
            "       Photography       0.00      0.00      0.00        38\n",
            "Science/Technology       0.50      0.75      0.60        32\n",
            "          Politics       0.43      0.67      0.53        43\n",
            "  Business/Finance       0.63      0.59      0.61        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.76      0.44      0.56        43\n",
            "              Food       0.75      0.43      0.55        35\n",
            "               AMA       0.93      0.62      0.75        45\n",
            "\n",
            "          accuracy                           0.48       461\n",
            "         macro avg       0.49      0.48      0.45       461\n",
            "      weighted avg       0.50      0.48      0.46       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fffogbRCEgsD",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 SGD/LinearSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jext-7jaD75J",
        "colab_type": "code",
        "outputId": "b7b53ab0-b97e-4c64-d2f6-b246ac3d0fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "sgd.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = sgd.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5878524945770065\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.61      0.79      0.69        34\n",
            "     Non-Political       0.40      0.36      0.38        39\n",
            "       Reddiquette       0.44      0.46      0.45        41\n",
            "         Scheduled       0.70      0.78      0.74        36\n",
            "       Photography       0.21      0.16      0.18        38\n",
            "Science/Technology       0.67      0.75      0.71        32\n",
            "          Politics       0.54      0.63      0.58        43\n",
            "  Business/Finance       0.70      0.80      0.74        44\n",
            "    Policy/Economy       0.65      0.35      0.46        31\n",
            "            Sports       0.68      0.65      0.67        43\n",
            "              Food       0.63      0.63      0.63        35\n",
            "               AMA       0.71      0.67      0.69        45\n",
            "\n",
            "          accuracy                           0.59       461\n",
            "         macro avg       0.58      0.59      0.58       461\n",
            "      weighted avg       0.58      0.59      0.58       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SfAGIxzFBJu",
        "colab_type": "text"
      },
      "source": [
        "### 4.3 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd_5NlghEr7A",
        "colab_type": "code",
        "outputId": "4411f513-ec24-4492-8821-96aec7cd0fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "logreg.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5683297180043384\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.68      0.74      0.70        34\n",
            "     Non-Political       0.34      0.51      0.41        39\n",
            "       Reddiquette       0.46      0.54      0.49        41\n",
            "         Scheduled       0.78      0.69      0.74        36\n",
            "       Photography       0.15      0.16      0.16        38\n",
            "Science/Technology       0.59      0.69      0.64        32\n",
            "          Politics       0.51      0.53      0.52        43\n",
            "  Business/Finance       0.69      0.77      0.73        44\n",
            "    Policy/Economy       0.60      0.39      0.47        31\n",
            "            Sports       0.75      0.56      0.64        43\n",
            "              Food       0.64      0.60      0.62        35\n",
            "               AMA       0.90      0.62      0.74        45\n",
            "\n",
            "          accuracy                           0.57       461\n",
            "         macro avg       0.59      0.57      0.57       461\n",
            "      weighted avg       0.60      0.57      0.57       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XMJYS1oFwQj",
        "colab_type": "text"
      },
      "source": [
        "### 4.4 AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJrGg56mFF-F",
        "colab_type": "code",
        "outputId": "fa4f3716-eb29-48c3-dd6d-9b150401a608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "ada.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.3318872017353579\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.56      0.29      0.38        34\n",
            "     Non-Political       0.16      0.26      0.20        39\n",
            "       Reddiquette       0.29      0.44      0.35        41\n",
            "         Scheduled       0.59      0.47      0.52        36\n",
            "       Photography       0.12      0.39      0.19        38\n",
            "Science/Technology       0.45      0.31      0.37        32\n",
            "          Politics       0.26      0.26      0.26        43\n",
            "  Business/Finance       0.62      0.36      0.46        44\n",
            "    Policy/Economy       0.20      0.03      0.06        31\n",
            "            Sports       0.74      0.40      0.52        43\n",
            "              Food       0.33      0.31      0.32        35\n",
            "               AMA       0.94      0.38      0.54        45\n",
            "\n",
            "          accuracy                           0.33       461\n",
            "         macro avg       0.44      0.33      0.35       461\n",
            "      weighted avg       0.45      0.33      0.35       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y0_MMcrF231",
        "colab_type": "text"
      },
      "source": [
        "### 4.5 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF77AY9qF1Ev",
        "colab_type": "code",
        "outputId": "ba7eb07f-b423-4133-d01d-88fa83cdbbda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "ranfor.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5639913232104121\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.64      0.74      0.68        34\n",
            "     Non-Political       0.50      0.46      0.48        39\n",
            "       Reddiquette       0.53      0.44      0.48        41\n",
            "         Scheduled       0.72      0.72      0.72        36\n",
            "       Photography       0.18      0.34      0.24        38\n",
            "Science/Technology       0.47      0.72      0.57        32\n",
            "          Politics       0.62      0.53      0.57        43\n",
            "  Business/Finance       0.71      0.82      0.76        44\n",
            "    Policy/Economy       0.83      0.16      0.27        31\n",
            "            Sports       0.81      0.51      0.63        43\n",
            "              Food       0.57      0.57      0.57        35\n",
            "               AMA       0.78      0.69      0.73        45\n",
            "\n",
            "          accuracy                           0.56       461\n",
            "         macro avg       0.61      0.56      0.56       461\n",
            "      weighted avg       0.62      0.56      0.57       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sOMwjqkGUID",
        "colab_type": "text"
      },
      "source": [
        "### 4.6 MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vezWFujsGYPC",
        "colab_type": "code",
        "outputId": "dabdb864-c639-44ef-8732-248f52ba9767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "mlp.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5119305856832972\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.70      0.62      0.66        34\n",
            "     Non-Political       0.40      0.31      0.35        39\n",
            "       Reddiquette       0.49      0.46      0.48        41\n",
            "         Scheduled       0.71      0.67      0.69        36\n",
            "       Photography       0.11      0.18      0.14        38\n",
            "Science/Technology       0.57      0.53      0.55        32\n",
            "          Politics       0.45      0.51      0.48        43\n",
            "  Business/Finance       0.62      0.64      0.63        44\n",
            "    Policy/Economy       0.60      0.29      0.39        31\n",
            "            Sports       0.64      0.63      0.64        43\n",
            "              Food       0.43      0.66      0.52        35\n",
            "               AMA       0.87      0.60      0.71        45\n",
            "\n",
            "          accuracy                           0.51       461\n",
            "         macro avg       0.55      0.51      0.52       461\n",
            "      weighted avg       0.55      0.51      0.52       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZrxi9BEHAfm",
        "colab_type": "text"
      },
      "source": [
        "## 3. Multivariate Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g-k5-6xHF_-",
        "colab_type": "text"
      },
      "source": [
        "### Combining title, comments and body\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsrv01RQGi4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X5_test = X_test['title'] + X_test['comm'] + X_test['body']\n",
        "X5_train = X_train['title'] + X_train['comm'] + X_train['body']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw_DfhcpJjj5",
        "colab_type": "text"
      },
      "source": [
        "### 1. Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vi6UUhbISKA",
        "colab_type": "code",
        "outputId": "3bb1506f-922e-41a6-a6f2-57c7bfc8c801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "nb.fit(X5_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6030368763557483\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.34      0.88      0.49        34\n",
            "     Non-Political       0.48      0.56      0.52        39\n",
            "       Reddiquette       0.50      0.78      0.61        41\n",
            "         Scheduled       0.75      0.75      0.75        36\n",
            "       Photography       1.00      0.16      0.27        38\n",
            "Science/Technology       0.84      0.81      0.83        32\n",
            "          Politics       0.51      0.74      0.60        43\n",
            "  Business/Finance       0.71      0.55      0.62        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.92      0.56      0.70        43\n",
            "              Food       0.76      0.63      0.69        35\n",
            "               AMA       0.89      0.73      0.80        45\n",
            "\n",
            "          accuracy                           0.60       461\n",
            "         macro avg       0.64      0.60      0.57       461\n",
            "      weighted avg       0.65      0.60      0.58       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otmlES8eJpBg",
        "colab_type": "text"
      },
      "source": [
        "### 2. SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43sTzWs1IjPn",
        "colab_type": "code",
        "outputId": "c02b1232-28c4-4642-d67b-7dd6e4482e3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "sgd1 = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
        "               ])\n",
        "\n",
        "sgd1.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = sgd1.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.7852494577006508\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.76      0.94      0.84        34\n",
            "     Non-Political       0.78      0.72      0.75        39\n",
            "       Reddiquette       0.74      0.76      0.75        41\n",
            "         Scheduled       0.78      0.86      0.82        36\n",
            "       Photography       0.74      0.68      0.71        38\n",
            "Science/Technology       0.83      0.94      0.88        32\n",
            "          Politics       0.74      0.74      0.74        43\n",
            "  Business/Finance       0.84      0.82      0.83        44\n",
            "    Policy/Economy       0.95      0.58      0.72        31\n",
            "            Sports       0.80      0.81      0.80        43\n",
            "              Food       0.68      0.74      0.71        35\n",
            "               AMA       0.86      0.82      0.84        45\n",
            "\n",
            "          accuracy                           0.79       461\n",
            "         macro avg       0.79      0.79      0.78       461\n",
            "      weighted avg       0.79      0.79      0.78       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvywgCkCJ0G1",
        "colab_type": "text"
      },
      "source": [
        "###3. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vepJ8fX2JwiC",
        "colab_type": "code",
        "outputId": "1088752e-35bc-4880-eb81-99fef7d6a68f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "logreg.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.7483731019522777\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.79      0.76      0.78        34\n",
            "     Non-Political       0.58      0.82      0.68        39\n",
            "       Reddiquette       0.76      0.68      0.72        41\n",
            "         Scheduled       0.79      0.86      0.83        36\n",
            "       Photography       0.69      0.63      0.66        38\n",
            "Science/Technology       0.88      0.88      0.88        32\n",
            "          Politics       0.71      0.67      0.69        43\n",
            "  Business/Finance       0.72      0.75      0.73        44\n",
            "    Policy/Economy       0.95      0.58      0.72        31\n",
            "            Sports       0.77      0.79      0.78        43\n",
            "              Food       0.65      0.74      0.69        35\n",
            "               AMA       0.90      0.80      0.85        45\n",
            "\n",
            "          accuracy                           0.75       461\n",
            "         macro avg       0.76      0.75      0.75       461\n",
            "      weighted avg       0.76      0.75      0.75       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuXlijt0L0qJ",
        "colab_type": "text"
      },
      "source": [
        "### 4. AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deUo3MmaKCM-",
        "colab_type": "code",
        "outputId": "125cd8c0-615c-4e33-f766-29824568fbda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "ada.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5162689804772235\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.52      0.44      0.48        34\n",
            "     Non-Political       0.42      0.38      0.40        39\n",
            "       Reddiquette       0.82      0.68      0.75        41\n",
            "         Scheduled       0.39      0.53      0.45        36\n",
            "       Photography       0.50      0.37      0.42        38\n",
            "Science/Technology       0.84      0.66      0.74        32\n",
            "          Politics       0.47      0.42      0.44        43\n",
            "  Business/Finance       0.23      0.57      0.33        44\n",
            "    Policy/Economy       0.94      0.48      0.64        31\n",
            "            Sports       0.54      0.44      0.49        43\n",
            "              Food       0.79      0.74      0.76        35\n",
            "               AMA       0.79      0.51      0.62        45\n",
            "\n",
            "          accuracy                           0.52       461\n",
            "         macro avg       0.60      0.52      0.54       461\n",
            "      weighted avg       0.59      0.52      0.54       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtOp60h6L_z1",
        "colab_type": "text"
      },
      "source": [
        "### 5. Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4294zJcYL7np",
        "colab_type": "code",
        "outputId": "ae42c738-3670-43d2-c84a-9bac4692468c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "ranfor.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.8112798264642083\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.85      0.85      0.85        34\n",
            "     Non-Political       0.74      0.90      0.81        39\n",
            "       Reddiquette       0.78      0.76      0.77        41\n",
            "         Scheduled       0.84      0.86      0.85        36\n",
            "       Photography       0.72      0.76      0.74        38\n",
            "Science/Technology       0.78      0.88      0.82        32\n",
            "          Politics       0.79      0.77      0.78        43\n",
            "  Business/Finance       0.80      0.82      0.81        44\n",
            "    Policy/Economy       1.00      0.65      0.78        31\n",
            "            Sports       0.89      0.77      0.82        43\n",
            "              Food       0.68      0.80      0.74        35\n",
            "               AMA       0.98      0.91      0.94        45\n",
            "\n",
            "          accuracy                           0.81       461\n",
            "         macro avg       0.82      0.81      0.81       461\n",
            "      weighted avg       0.82      0.81      0.81       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CekS2NInMITb",
        "colab_type": "text"
      },
      "source": [
        "### 6. MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRH5v4yKMG-j",
        "colab_type": "code",
        "outputId": "58720923-d182-4a17-a0bd-9cab1bf9b776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "mlp.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6767895878524945\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.89      0.71      0.79        34\n",
            "     Non-Political       0.47      0.77      0.58        39\n",
            "       Reddiquette       0.78      0.61      0.68        41\n",
            "         Scheduled       0.78      0.81      0.79        36\n",
            "       Photography       0.49      0.66      0.56        38\n",
            "Science/Technology       0.74      0.81      0.78        32\n",
            "          Politics       0.60      0.67      0.64        43\n",
            "  Business/Finance       0.66      0.57      0.61        44\n",
            "    Policy/Economy       0.91      0.32      0.48        31\n",
            "            Sports       0.74      0.74      0.74        43\n",
            "              Food       0.64      0.60      0.62        35\n",
            "               AMA       0.86      0.80      0.83        45\n",
            "\n",
            "          accuracy                           0.68       461\n",
            "         macro avg       0.71      0.67      0.67       461\n",
            "      weighted avg       0.71      0.68      0.68       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbiLIBeoNCxw",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest performed the best with title, comments and body as features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QluvvuqSuG2",
        "colab_type": "text"
      },
      "source": [
        "### Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H40QavkdMhZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'final_model1.sav'\n",
        "pickle.dump(ranfor, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZWfzCEAVv_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}