{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX0YtJEL9OCZ",
        "colab_type": "code",
        "outputId": "04b38730-6653-492d-c748-4e0352237a11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!pip install pymongo\n",
        "\n",
        "import logging\n",
        "import json\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from numpy import random\n",
        "import gensim\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import pickle"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (3.9.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHVoh1KI8Nm2",
        "colab_type": "text"
      },
      "source": [
        "## Getting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxPVFxLX9WXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "client = MongoClient('mongodb://nitish:umeshpapa123@cluster0-shard-00-00-ifnda.mongodb.net:27017,cluster0-shard-00-01-ifnda.mongodb.net:27017,cluster0-shard-00-02-ifnda.mongodb.net:27017/test?ssl=true&replicaSet=Cluster0-shard-0&authSource=admin&retryWrites=true&w=majority')\n",
        "db = client.database\n",
        "collection = db.data_collection\n",
        "posts = db.posts\n",
        "data = posts.find_one()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLQa4xvs-OK3",
        "colab_type": "code",
        "outputId": "cc6f56c9-6196-4391-9e08-9580f40b5eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "data = pd.DataFrame(data)\n",
        "plt.figure(figsize=(10,4))\n",
        "data.flair.value_counts().plot(kind='bar');\n",
        "flairs = [\"AskIndia\", \"Non-Political\", \"Reddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\", \"AMA\"]\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAFVCAYAAAA35UGiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXjcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkgRsdxq-SY_",
        "colab_type": "code",
        "outputId": "1e180d5f-b9d8-4fb5-c45b-f7eb38f1296d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "source": [
        "data = data.drop(columns=\"_id\")\n",
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flair</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>score</th>\n",
              "      <th>url</th>\n",
              "      <th>num_comm</th>\n",
              "      <th>created</th>\n",
              "      <th>id</th>\n",
              "      <th>author</th>\n",
              "      <th>comm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>Need feedback for Insurance Policy that I took...</td>\n",
              "      <td>**Re-posting here because of lack of activity ...</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/1s57oi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.386254e+09</td>\n",
              "      <td>1s57oi</td>\n",
              "      <td>dhavalcoholic</td>\n",
              "      <td>Dear Policy Holder(Dhavalcoholic),\\n \\nWe req...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>Somebody want to kill my full family what to do?</td>\n",
              "      <td>It's now 24hrs, But local police station is no...</td>\n",
              "      <td>92</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/b7pvwt...</td>\n",
              "      <td>24</td>\n",
              "      <td>1.554080e+09</td>\n",
              "      <td>b7pvwt</td>\n",
              "      <td>amitkumarthakur</td>\n",
              "      <td>Calm down.\\nGo to the SP office of your town,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>Ambassador of India takes back my newly issued...</td>\n",
              "      <td>Hello /AskIndia!  First time poster, long time...</td>\n",
              "      <td>13</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/bdfid1...</td>\n",
              "      <td>27</td>\n",
              "      <td>1.555361e+09</td>\n",
              "      <td>bdfid1</td>\n",
              "      <td>FrustratedOCIHopeful</td>\n",
              "      <td>Honestly, she and her supervisor behaved *exa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>Randians, what are you too afraid to ask?</td>\n",
              "      <td>r/TooAfraidToAsk India edition</td>\n",
              "      <td>16</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/cu1xn4...</td>\n",
              "      <td>22</td>\n",
              "      <td>1.566529e+09</td>\n",
              "      <td>cu1xn4</td>\n",
              "      <td>aloo_vs_bhaloo</td>\n",
              "      <td>How does Modi control his sex desires? Or if ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>[AskIndia] Cingari, Cengar or Tzengar?</td>\n",
              "      <td>Hello,\\n\\nI submitted this to /r/rAskIndia a w...</td>\n",
              "      <td>0</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/18ntue...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.361085e+09</td>\n",
              "      <td>18ntue</td>\n",
              "      <td>multubunu</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      flair  ...                                               comm\n",
              "0  AskIndia  ...   Dear Policy Holder(Dhavalcoholic),\\n \\nWe req...\n",
              "1  AskIndia  ...   Calm down.\\nGo to the SP office of your town,...\n",
              "2  AskIndia  ...   Honestly, she and her supervisor behaved *exa...\n",
              "3  AskIndia  ...   How does Modi control his sex desires? Or if ...\n",
              "4  AskIndia  ...                                                   \n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5klpYDR7gqC",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-QfbU0y7jlP",
        "colab_type": "code",
        "outputId": "52fd3b2a-40f4-401d-9f45-7441e46d2567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    return text\n",
        "  \n",
        "def todate(created):\n",
        "    return dt.datetime.fromtimestamp(created)\n",
        "  \n",
        "try:\n",
        "  created = data[\"created\"].apply(todate)\n",
        "  data = data.assign(created = created)\n",
        "except:\n",
        "  print(\"already timestamp\")\n",
        "\n",
        "def tostr(value):\n",
        "    return str(value)\n",
        "  \n",
        "data['title'] = data['title'].apply(tostr)\n",
        "data['title'] = data['title'].apply(clean_text)\n",
        "data['body'] = data['body'].apply(tostr)\n",
        "data['body'] = data['body'].apply(clean_text)\n",
        "data['comm'] = data['comm'].apply(tostr)\n",
        "data['comm'] = data['comm'].apply(clean_text)\n",
        "data['url'] = data['url'].apply(tostr)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://youtu.be/kBvIqVr__C0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n30eEh41Gb8y",
        "colab_type": "code",
        "outputId": "65af26ba-18b6-4681-ff67-6c6a1d393812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "source": [
        "data.tail()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flair</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>score</th>\n",
              "      <th>url</th>\n",
              "      <th>num_comm</th>\n",
              "      <th>created</th>\n",
              "      <th>id</th>\n",
              "      <th>author</th>\n",
              "      <th>comm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2296</th>\n",
              "      <td>AMA</td>\n",
              "      <td>r india met spent time celebrity actors anyone...</td>\n",
              "      <td></td>\n",
              "      <td>33</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/1u5caw...</td>\n",
              "      <td>168</td>\n",
              "      <td>2014-01-01 15:40:35</td>\n",
              "      <td>1u5caw</td>\n",
              "      <td>varuval</td>\n",
              "      <td>true storyi peed standing next ratan tata los ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2297</th>\n",
              "      <td>AMA</td>\n",
              "      <td>upcoming ama rocky mayur monday 4th august 120...</td>\n",
              "      <td>rocky singh mayur sharma childhood friends tog...</td>\n",
              "      <td>83</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/2cesw5...</td>\n",
              "      <td>59</td>\n",
              "      <td>2014-08-02 16:28:37</td>\n",
              "      <td>2cesw5</td>\n",
              "      <td>rahulthewall</td>\n",
              "      <td>welcome guys http wwwredditcom r india comment...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2298</th>\n",
              "      <td>AMA</td>\n",
              "      <td>friend completed cycling 6200 kms kashmir kany...</td>\n",
              "      <td></td>\n",
              "      <td>455</td>\n",
              "      <td>http://imgur.com/fv9DA</td>\n",
              "      <td>62</td>\n",
              "      <td>2013-01-06 20:38:16</td>\n",
              "      <td>1624gc</td>\n",
              "      <td>petty86</td>\n",
              "      <td>great achievement indeed convince ama listed e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2299</th>\n",
              "      <td>AMA</td>\n",
              "      <td>priyanka chopras reaction ama</td>\n",
              "      <td></td>\n",
              "      <td>94</td>\n",
              "      <td>http://gfycat.com/InsistentFlamboyantInganue</td>\n",
              "      <td>59</td>\n",
              "      <td>2014-07-03 04:39:38</td>\n",
              "      <td>29ojfi</td>\n",
              "      <td>DesiGif</td>\n",
              "      <td>one new profiles pr team created asked last ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2300</th>\n",
              "      <td>AMA</td>\n",
              "      <td>hey reddit im anoop bhat draw stuff pen ink ba...</td>\n",
              "      <td>hi im anoop architect freelance illustrator ba...</td>\n",
              "      <td>147</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/84lr68...</td>\n",
              "      <td>103</td>\n",
              "      <td>2018-03-15 19:32:47</td>\n",
              "      <td>84lr68</td>\n",
              "      <td>scourgwreck</td>\n",
              "      <td>hi anoopdo sell posters online ship outside in...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     flair  ...                                               comm\n",
              "2296   AMA  ...  true storyi peed standing next ratan tata los ...\n",
              "2297   AMA  ...  welcome guys http wwwredditcom r india comment...\n",
              "2298   AMA  ...  great achievement indeed convince ama listed e...\n",
              "2299   AMA  ...  one new profiles pr team created asked last ti...\n",
              "2300   AMA  ...  hi anoopdo sell posters online ship outside in...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SosgjCUCOP0a",
        "colab_type": "text"
      },
      "source": [
        "## 1. Feature #1 : Title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy0VsCtWQRAX",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl51oLlCOSbi",
        "colab_type": "code",
        "outputId": "dfdafa39-2bd8-4626-9347-3cf8a243a727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Only taking title, body, url, comments as features as they have the most\n",
        "# significant amount of natural language related to the flair\n",
        "\n",
        "X = data[['title', 'body', 'url', 'comm']]\n",
        "y = data['flair']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "\n",
        "X1_train = X_train['title']\n",
        "X1_test = X_test['title']\n",
        "\n",
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "nb.fit(X1_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6268980477223427\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.61      0.65      0.63        34\n",
            "     Non-Political       0.53      0.85      0.65        39\n",
            "       Reddiquette       0.59      0.39      0.47        41\n",
            "         Scheduled       0.69      0.75      0.72        36\n",
            "       Photography       0.77      0.95      0.85        38\n",
            "Science/Technology       0.51      0.75      0.61        32\n",
            "          Politics       0.53      0.58      0.56        43\n",
            "  Business/Finance       0.59      0.45      0.51        44\n",
            "    Policy/Economy       1.00      0.16      0.28        31\n",
            "            Sports       0.68      0.60      0.64        43\n",
            "              Food       0.58      0.60      0.59        35\n",
            "               AMA       0.79      0.76      0.77        45\n",
            "\n",
            "          accuracy                           0.63       461\n",
            "         macro avg       0.66      0.62      0.61       461\n",
            "      weighted avg       0.65      0.63      0.61       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uRe9Im9QXGp",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 SGD/LinearSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqg2PSjaPA6C",
        "colab_type": "code",
        "outputId": "4f92927f-668b-409b-866e-08886bae5cd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
        "               ])\n",
        "sgd.fit(X1_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = sgd.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6919739696312365\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.65      0.71      0.68        34\n",
            "     Non-Political       0.78      0.90      0.83        39\n",
            "       Reddiquette       0.59      0.41      0.49        41\n",
            "         Scheduled       0.68      0.78      0.73        36\n",
            "       Photography       0.84      1.00      0.92        38\n",
            "Science/Technology       0.75      0.75      0.75        32\n",
            "          Politics       0.53      0.53      0.53        43\n",
            "  Business/Finance       0.65      0.50      0.56        44\n",
            "    Policy/Economy       0.76      0.61      0.68        31\n",
            "            Sports       0.70      0.72      0.71        43\n",
            "              Food       0.61      0.57      0.59        35\n",
            "               AMA       0.72      0.84      0.78        45\n",
            "\n",
            "          accuracy                           0.69       461\n",
            "         macro avg       0.69      0.69      0.69       461\n",
            "      weighted avg       0.69      0.69      0.68       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqOzt5g3Q156",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u5sQRStQmhA",
        "colab_type": "code",
        "outputId": "42409745-dad7-4780-8260-da8b7e35c0f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
        "               ])\n",
        "logreg.fit(X1_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6963123644251626\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.70      0.76      0.73        34\n",
            "     Non-Political       0.83      0.90      0.86        39\n",
            "       Reddiquette       0.56      0.46      0.51        41\n",
            "         Scheduled       0.70      0.78      0.74        36\n",
            "       Photography       0.93      0.97      0.95        38\n",
            "Science/Technology       0.70      0.72      0.71        32\n",
            "          Politics       0.62      0.60      0.61        43\n",
            "  Business/Finance       0.59      0.45      0.51        44\n",
            "    Policy/Economy       0.87      0.65      0.74        31\n",
            "            Sports       0.66      0.67      0.67        43\n",
            "              Food       0.62      0.57      0.60        35\n",
            "               AMA       0.63      0.84      0.72        45\n",
            "\n",
            "          accuracy                           0.70       461\n",
            "         macro avg       0.70      0.70      0.70       461\n",
            "      weighted avg       0.69      0.70      0.69       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkrWHgCDSjWj",
        "colab_type": "text"
      },
      "source": [
        "### 1.4 AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-7GjUNwSlyA",
        "colab_type": "code",
        "outputId": "c2a324fb-ccf2-4c27-9275-87fe0fa573c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', AdaBoostClassifier(n_estimators = 500, learning_rate=0.9)),\n",
        "               ])\n",
        "ada.fit(X1_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.4078091106290672\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.95      0.56      0.70        34\n",
            "     Non-Political       0.92      0.87      0.89        39\n",
            "       Reddiquette       0.13      0.93      0.23        41\n",
            "         Scheduled       0.88      0.58      0.70        36\n",
            "       Photography       1.00      0.03      0.05        38\n",
            "Science/Technology       1.00      0.56      0.72        32\n",
            "          Politics       0.00      0.00      0.00        43\n",
            "  Business/Finance       0.00      0.00      0.00        44\n",
            "    Policy/Economy       0.86      0.58      0.69        31\n",
            "            Sports       1.00      0.40      0.57        43\n",
            "              Food       0.90      0.26      0.40        35\n",
            "               AMA       0.93      0.29      0.44        45\n",
            "\n",
            "          accuracy                           0.41       461\n",
            "         macro avg       0.71      0.42      0.45       461\n",
            "      weighted avg       0.69      0.41      0.43       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2hBfrV2WF9b",
        "colab_type": "text"
      },
      "source": [
        "### 1.5 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax_-PNk1WH9_",
        "colab_type": "code",
        "outputId": "387f93c5-ac74-4d85-d080-b8290a7c34a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "  \n",
        "ranfor = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', RandomForestClassifier(n_estimators = 500, random_state = 42)),\n",
        "                 ])\n",
        "ranfor.fit(X1_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6550976138828634\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.64      0.62      0.63        34\n",
            "     Non-Political       0.88      0.90      0.89        39\n",
            "       Reddiquette       0.47      0.51      0.49        41\n",
            "         Scheduled       0.71      0.81      0.75        36\n",
            "       Photography       0.93      0.97      0.95        38\n",
            "Science/Technology       0.65      0.69      0.67        32\n",
            "          Politics       0.45      0.56      0.50        43\n",
            "  Business/Finance       0.54      0.45      0.49        44\n",
            "    Policy/Economy       0.95      0.58      0.72        31\n",
            "            Sports       0.74      0.53      0.62        43\n",
            "              Food       0.43      0.51      0.47        35\n",
            "               AMA       0.74      0.76      0.75        45\n",
            "\n",
            "          accuracy                           0.66       461\n",
            "         macro avg       0.68      0.66      0.66       461\n",
            "      weighted avg       0.67      0.66      0.66       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18Lqp9jGX_BB",
        "colab_type": "text"
      },
      "source": [
        "### 1.6 MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plePunVAYDrf",
        "colab_type": "code",
        "outputId": "83d0c342-6ed5-4cba-f16d-9f8da07d9f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "  \n",
        "mlp = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', MLPClassifier(hidden_layer_sizes=(35,35,35), alpha=0.1, random_state=42, max_iter=200)),\n",
        "                 ])\n",
        "  \n",
        "mlp.fit(X1_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6507592190889371\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.55      0.71      0.62        34\n",
            "     Non-Political       0.81      0.87      0.84        39\n",
            "       Reddiquette       0.54      0.37      0.43        41\n",
            "         Scheduled       0.71      0.67      0.69        36\n",
            "       Photography       0.92      0.95      0.94        38\n",
            "Science/Technology       0.74      0.72      0.73        32\n",
            "          Politics       0.40      0.67      0.50        43\n",
            "  Business/Finance       0.42      0.50      0.46        44\n",
            "    Policy/Economy       0.93      0.45      0.61        31\n",
            "            Sports       0.83      0.67      0.74        43\n",
            "              Food       0.63      0.49      0.55        35\n",
            "               AMA       0.80      0.73      0.77        45\n",
            "\n",
            "          accuracy                           0.65       461\n",
            "         macro avg       0.69      0.65      0.66       461\n",
            "      weighted avg       0.68      0.65      0.65       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmEecWPMcXlo",
        "colab_type": "text"
      },
      "source": [
        "## 2. Feature #2 : Body"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBdw0kFNchE5",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxP91vMHagKQ",
        "colab_type": "code",
        "outputId": "407854e9-fb63-407a-e186-b661ea7d5014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "X2_train = X_train['body']\n",
        "X2_test = X_test['body']\n",
        "\n",
        "nb.fit(X2_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.23644251626898047\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.67      0.29      0.41        34\n",
            "     Non-Political       0.34      0.54      0.42        39\n",
            "       Reddiquette       0.23      0.68      0.34        41\n",
            "         Scheduled       0.33      0.03      0.05        36\n",
            "       Photography       0.00      0.00      0.00        38\n",
            "Science/Technology       0.12      0.84      0.21        32\n",
            "          Politics       1.00      0.02      0.05        43\n",
            "  Business/Finance       0.00      0.00      0.00        44\n",
            "    Policy/Economy       1.00      0.16      0.28        31\n",
            "            Sports       0.50      0.07      0.12        43\n",
            "              Food       0.71      0.29      0.41        35\n",
            "               AMA       0.60      0.07      0.12        45\n",
            "\n",
            "          accuracy                           0.24       461\n",
            "         macro avg       0.46      0.25      0.20       461\n",
            "      weighted avg       0.45      0.24      0.19       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5pah0AT8Xzq",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 SGD/LinearSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwlavI2k8OHB",
        "colab_type": "code",
        "outputId": "565b07f3-1b6e-46e0-facb-24dac5f2668b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "sgd.fit(X2_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = sgd.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.3665943600867679\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.60      0.44      0.51        34\n",
            "     Non-Political       0.45      0.46      0.46        39\n",
            "       Reddiquette       0.49      0.56      0.52        41\n",
            "         Scheduled       0.41      0.19      0.26        36\n",
            "       Photography       0.25      0.03      0.05        38\n",
            "Science/Technology       0.47      0.28      0.35        32\n",
            "          Politics       0.50      0.14      0.22        43\n",
            "  Business/Finance       0.17      0.82      0.28        44\n",
            "    Policy/Economy       0.79      0.61      0.69        31\n",
            "            Sports       0.55      0.14      0.22        43\n",
            "              Food       0.55      0.46      0.50        35\n",
            "               AMA       0.72      0.29      0.41        45\n",
            "\n",
            "          accuracy                           0.37       461\n",
            "         macro avg       0.50      0.37      0.37       461\n",
            "      weighted avg       0.49      0.37      0.36       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ck3492B9VaC",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndnqdtaz9Fq3",
        "colab_type": "code",
        "outputId": "699c41c9-eca7-4ac7-ae85-020ed51ba665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "logreg.fit(X2_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.3362255965292842\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.52      0.41      0.46        34\n",
            "     Non-Political       0.37      0.49      0.42        39\n",
            "       Reddiquette       0.58      0.51      0.55        41\n",
            "         Scheduled       0.50      0.19      0.28        36\n",
            "       Photography       0.08      0.03      0.04        38\n",
            "Science/Technology       0.45      0.28      0.35        32\n",
            "          Politics       0.38      0.12      0.18        43\n",
            "  Business/Finance       0.16      0.82      0.27        44\n",
            "    Policy/Economy       0.84      0.52      0.64        31\n",
            "            Sports       0.60      0.14      0.23        43\n",
            "              Food       0.47      0.40      0.43        35\n",
            "               AMA       0.70      0.16      0.25        45\n",
            "\n",
            "          accuracy                           0.34       461\n",
            "         macro avg       0.47      0.34      0.34       461\n",
            "      weighted avg       0.47      0.34      0.33       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1p8DH1n9oFy",
        "colab_type": "text"
      },
      "source": [
        "### 2.4 AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfauWsRe9tBM",
        "colab_type": "code",
        "outputId": "38bb0c84-8bd5-420b-d47e-1d24d5a46bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "ada.fit(X2_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.23644251626898047\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.27      0.24      0.25        34\n",
            "     Non-Political       0.21      0.44      0.28        39\n",
            "       Reddiquette       0.65      0.27      0.38        41\n",
            "         Scheduled       0.30      0.08      0.13        36\n",
            "       Photography       0.09      0.08      0.09        38\n",
            "Science/Technology       0.46      0.19      0.27        32\n",
            "          Politics       0.33      0.12      0.17        43\n",
            "  Business/Finance       0.16      0.82      0.27        44\n",
            "    Policy/Economy       0.71      0.16      0.26        31\n",
            "            Sports       0.56      0.12      0.19        43\n",
            "              Food       0.30      0.09      0.13        35\n",
            "               AMA       0.44      0.16      0.23        45\n",
            "\n",
            "          accuracy                           0.24       461\n",
            "         macro avg       0.37      0.23      0.22       461\n",
            "      weighted avg       0.37      0.24      0.22       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzsBh189-NG_",
        "colab_type": "text"
      },
      "source": [
        "### 2.5 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9RXz2Oz95O6",
        "colab_type": "code",
        "outputId": "d6842197-44e4-4d21-bfa6-935600f0c3a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "ranfor.fit(X2_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.3644251626898048\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.56      0.41      0.47        34\n",
            "     Non-Political       0.35      0.72      0.47        39\n",
            "       Reddiquette       0.64      0.61      0.62        41\n",
            "         Scheduled       0.45      0.14      0.21        36\n",
            "       Photography       0.00      0.00      0.00        38\n",
            "Science/Technology       0.75      0.28      0.41        32\n",
            "          Politics       0.60      0.21      0.31        43\n",
            "  Business/Finance       0.16      0.80      0.27        44\n",
            "    Policy/Economy       1.00      0.52      0.68        31\n",
            "            Sports       0.50      0.07      0.12        43\n",
            "              Food       0.80      0.46      0.58        35\n",
            "               AMA       0.53      0.18      0.27        45\n",
            "\n",
            "          accuracy                           0.36       461\n",
            "         macro avg       0.53      0.37      0.37       461\n",
            "      weighted avg       0.51      0.36      0.36       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zh_y9Rm-ewa",
        "colab_type": "text"
      },
      "source": [
        "### 2.6 MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xhYXP1E-WM0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "8696db3e-45e1-4388-8756-b9d0386cbfee"
      },
      "source": [
        "mlp.fit(X2_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.2950108459869848\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.40      0.24      0.30        34\n",
            "     Non-Political       0.41      0.28      0.33        39\n",
            "       Reddiquette       0.61      0.46      0.53        41\n",
            "         Scheduled       0.44      0.19      0.27        36\n",
            "       Photography       0.08      0.03      0.04        38\n",
            "Science/Technology       0.39      0.28      0.33        32\n",
            "          Politics       0.26      0.14      0.18        43\n",
            "  Business/Finance       0.16      0.84      0.27        44\n",
            "    Policy/Economy       0.80      0.39      0.52        31\n",
            "            Sports       0.43      0.07      0.12        43\n",
            "              Food       0.42      0.43      0.42        35\n",
            "               AMA       0.53      0.18      0.27        45\n",
            "\n",
            "          accuracy                           0.30       461\n",
            "         macro avg       0.41      0.29      0.30       461\n",
            "      weighted avg       0.40      0.30      0.29       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3erY2S1Y-ygW",
        "colab_type": "text"
      },
      "source": [
        "## 3. Feature #3 : Url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hHfBCkK_VNE",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knVuhJuC-rX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "460ab8ba-5f24-48e9-8f86-8fb27b486084"
      },
      "source": [
        "X3_train = X_train['url']\n",
        "X3_test = X_test['url']\n",
        "\n",
        "nb.fit(X3_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.27765726681127983\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.20      0.03      0.05        34\n",
            "     Non-Political       0.15      0.92      0.26        39\n",
            "       Reddiquette       0.43      0.07      0.12        41\n",
            "         Scheduled       0.38      0.33      0.35        36\n",
            "       Photography       0.33      0.18      0.24        38\n",
            "Science/Technology       0.46      0.19      0.27        32\n",
            "          Politics       0.57      0.37      0.45        43\n",
            "  Business/Finance       0.46      0.41      0.43        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.36      0.37      0.36        43\n",
            "              Food       0.39      0.20      0.26        35\n",
            "               AMA       0.60      0.13      0.22        45\n",
            "\n",
            "          accuracy                           0.28       461\n",
            "         macro avg       0.36      0.27      0.25       461\n",
            "      weighted avg       0.37      0.28      0.26       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_IJImFdAoqD",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 SGD/LinearSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6pGgYU4_a4z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "f75b7e43-a4fb-498e-8ad0-a5373194f287"
      },
      "source": [
        "sgd.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = sgd.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.29718004338394793\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.17      0.03      0.05        34\n",
            "     Non-Political       0.15      0.92      0.26        39\n",
            "       Reddiquette       0.44      0.10      0.16        41\n",
            "         Scheduled       0.60      0.17      0.26        36\n",
            "       Photography       0.29      0.18      0.23        38\n",
            "Science/Technology       0.62      0.16      0.25        32\n",
            "          Politics       0.58      0.42      0.49        43\n",
            "  Business/Finance       0.45      0.45      0.45        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.55      0.37      0.44        43\n",
            "              Food       0.43      0.26      0.32        35\n",
            "               AMA       0.39      0.33      0.36        45\n",
            "\n",
            "          accuracy                           0.30       461\n",
            "         macro avg       0.39      0.28      0.27       461\n",
            "      weighted avg       0.40      0.30      0.29       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzyeSRNNA0CL",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfDLbb_yAyVx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "30d37fc9-4c63-4d68-a986-3870a433457f"
      },
      "source": [
        "logreg.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.28633405639913234\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.25      0.03      0.05        34\n",
            "     Non-Political       0.15      0.92      0.26        39\n",
            "       Reddiquette       0.33      0.07      0.12        41\n",
            "         Scheduled       0.50      0.17      0.25        36\n",
            "       Photography       0.29      0.18      0.23        38\n",
            "Science/Technology       0.60      0.19      0.29        32\n",
            "          Politics       0.53      0.40      0.45        43\n",
            "  Business/Finance       0.46      0.39      0.42        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.43      0.37      0.40        43\n",
            "              Food       0.50      0.26      0.34        35\n",
            "               AMA       0.38      0.31      0.34        45\n",
            "\n",
            "          accuracy                           0.29       461\n",
            "         macro avg       0.37      0.27      0.26       461\n",
            "      weighted avg       0.37      0.29      0.27       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAjzohG0Bjes",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-NdBJwGBAg3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "1d7e4833-5b6f-4446-9a2c-b868826c70a7"
      },
      "source": [
        "ada.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.22559652928416485\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        34\n",
            "     Non-Political       0.15      0.97      0.25        39\n",
            "       Reddiquette       0.50      0.05      0.09        41\n",
            "         Scheduled       0.33      0.14      0.20        36\n",
            "       Photography       0.33      0.11      0.16        38\n",
            "Science/Technology       0.38      0.16      0.22        32\n",
            "          Politics       0.31      0.37      0.34        43\n",
            "  Business/Finance       0.30      0.52      0.38        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.25      0.05      0.08        43\n",
            "              Food       0.67      0.11      0.20        35\n",
            "               AMA       0.45      0.11      0.18        45\n",
            "\n",
            "          accuracy                           0.23       461\n",
            "         macro avg       0.31      0.22      0.17       461\n",
            "      weighted avg       0.31      0.23      0.18       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYN9e6qNBsnI",
        "colab_type": "text"
      },
      "source": [
        "### 3.5 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nG2KWRFBp34",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "187d85f1-ba72-4f89-a7f4-8709027d1394"
      },
      "source": [
        "ranfor.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.26247288503253796\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        34\n",
            "     Non-Political       0.00      0.00      0.00        39\n",
            "       Reddiquette       0.12      0.73      0.20        41\n",
            "         Scheduled       0.83      0.14      0.24        36\n",
            "       Photography       0.40      0.16      0.23        38\n",
            "Science/Technology       0.50      0.22      0.30        32\n",
            "          Politics       0.55      0.40      0.46        43\n",
            "  Business/Finance       0.41      0.52      0.46        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.54      0.30      0.39        43\n",
            "              Food       0.35      0.23      0.28        35\n",
            "               AMA       0.35      0.27      0.30        45\n",
            "\n",
            "          accuracy                           0.26       461\n",
            "         macro avg       0.34      0.25      0.24       461\n",
            "      weighted avg       0.34      0.26      0.25       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9LJgQPdCPgL",
        "colab_type": "text"
      },
      "source": [
        "### 3.6 MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTT2p78QBxzs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "669e7aac-3af2-472e-8721-f6d210c0955f"
      },
      "source": [
        "mlp.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.23644251626898047\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.20      0.03      0.05        34\n",
            "     Non-Political       1.00      0.03      0.05        39\n",
            "       Reddiquette       0.12      0.71      0.20        41\n",
            "         Scheduled       0.60      0.08      0.15        36\n",
            "       Photography       0.29      0.18      0.23        38\n",
            "Science/Technology       0.24      0.28      0.26        32\n",
            "          Politics       0.43      0.42      0.42        43\n",
            "  Business/Finance       0.37      0.32      0.34        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.42      0.26      0.32        43\n",
            "              Food       0.30      0.17      0.22        35\n",
            "               AMA       0.67      0.22      0.33        45\n",
            "\n",
            "          accuracy                           0.24       461\n",
            "         macro avg       0.39      0.22      0.21       461\n",
            "      weighted avg       0.40      0.24      0.22       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NP9Lw2GDOAc",
        "colab_type": "text"
      },
      "source": [
        "## 4. Feature #4 : Comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVi6tOtmDREO",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQg-kBb7CZUZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "d0ea609a-fe91-4dab-d9de-052ab1014fb3"
      },
      "source": [
        "X4_train = X_train['comm']\n",
        "X4_test = X_test['comm']\n",
        "\n",
        "nb.fit(X4_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.4837310195227766\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.23      0.91      0.37        34\n",
            "     Non-Political       0.33      0.28      0.31        39\n",
            "       Reddiquette       0.58      0.34      0.43        41\n",
            "         Scheduled       0.67      0.72      0.69        36\n",
            "       Photography       0.00      0.00      0.00        38\n",
            "Science/Technology       0.50      0.75      0.60        32\n",
            "          Politics       0.43      0.67      0.53        43\n",
            "  Business/Finance       0.63      0.59      0.61        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.76      0.44      0.56        43\n",
            "              Food       0.75      0.43      0.55        35\n",
            "               AMA       0.93      0.62      0.75        45\n",
            "\n",
            "          accuracy                           0.48       461\n",
            "         macro avg       0.49      0.48      0.45       461\n",
            "      weighted avg       0.50      0.48      0.46       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fffogbRCEgsD",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 SGD/LinearSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jext-7jaD75J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "b7b53ab0-b97e-4c64-d2f6-b246ac3d0fd0"
      },
      "source": [
        "sgd.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = sgd.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5878524945770065\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.61      0.79      0.69        34\n",
            "     Non-Political       0.40      0.36      0.38        39\n",
            "       Reddiquette       0.44      0.46      0.45        41\n",
            "         Scheduled       0.70      0.78      0.74        36\n",
            "       Photography       0.21      0.16      0.18        38\n",
            "Science/Technology       0.67      0.75      0.71        32\n",
            "          Politics       0.54      0.63      0.58        43\n",
            "  Business/Finance       0.70      0.80      0.74        44\n",
            "    Policy/Economy       0.65      0.35      0.46        31\n",
            "            Sports       0.68      0.65      0.67        43\n",
            "              Food       0.63      0.63      0.63        35\n",
            "               AMA       0.71      0.67      0.69        45\n",
            "\n",
            "          accuracy                           0.59       461\n",
            "         macro avg       0.58      0.59      0.58       461\n",
            "      weighted avg       0.58      0.59      0.58       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SfAGIxzFBJu",
        "colab_type": "text"
      },
      "source": [
        "### 4.3 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd_5NlghEr7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "4411f513-ec24-4492-8821-96aec7cd0fd7"
      },
      "source": [
        "logreg.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5683297180043384\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.68      0.74      0.70        34\n",
            "     Non-Political       0.34      0.51      0.41        39\n",
            "       Reddiquette       0.46      0.54      0.49        41\n",
            "         Scheduled       0.78      0.69      0.74        36\n",
            "       Photography       0.15      0.16      0.16        38\n",
            "Science/Technology       0.59      0.69      0.64        32\n",
            "          Politics       0.51      0.53      0.52        43\n",
            "  Business/Finance       0.69      0.77      0.73        44\n",
            "    Policy/Economy       0.60      0.39      0.47        31\n",
            "            Sports       0.75      0.56      0.64        43\n",
            "              Food       0.64      0.60      0.62        35\n",
            "               AMA       0.90      0.62      0.74        45\n",
            "\n",
            "          accuracy                           0.57       461\n",
            "         macro avg       0.59      0.57      0.57       461\n",
            "      weighted avg       0.60      0.57      0.57       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XMJYS1oFwQj",
        "colab_type": "text"
      },
      "source": [
        "### 4.4 AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJrGg56mFF-F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "fa4f3716-eb29-48c3-dd6d-9b150401a608"
      },
      "source": [
        "ada.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.3318872017353579\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.56      0.29      0.38        34\n",
            "     Non-Political       0.16      0.26      0.20        39\n",
            "       Reddiquette       0.29      0.44      0.35        41\n",
            "         Scheduled       0.59      0.47      0.52        36\n",
            "       Photography       0.12      0.39      0.19        38\n",
            "Science/Technology       0.45      0.31      0.37        32\n",
            "          Politics       0.26      0.26      0.26        43\n",
            "  Business/Finance       0.62      0.36      0.46        44\n",
            "    Policy/Economy       0.20      0.03      0.06        31\n",
            "            Sports       0.74      0.40      0.52        43\n",
            "              Food       0.33      0.31      0.32        35\n",
            "               AMA       0.94      0.38      0.54        45\n",
            "\n",
            "          accuracy                           0.33       461\n",
            "         macro avg       0.44      0.33      0.35       461\n",
            "      weighted avg       0.45      0.33      0.35       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y0_MMcrF231",
        "colab_type": "text"
      },
      "source": [
        "### 4.5 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF77AY9qF1Ev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "ba7eb07f-b423-4133-d01d-88fa83cdbbda"
      },
      "source": [
        "ranfor.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5639913232104121\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.64      0.74      0.68        34\n",
            "     Non-Political       0.50      0.46      0.48        39\n",
            "       Reddiquette       0.53      0.44      0.48        41\n",
            "         Scheduled       0.72      0.72      0.72        36\n",
            "       Photography       0.18      0.34      0.24        38\n",
            "Science/Technology       0.47      0.72      0.57        32\n",
            "          Politics       0.62      0.53      0.57        43\n",
            "  Business/Finance       0.71      0.82      0.76        44\n",
            "    Policy/Economy       0.83      0.16      0.27        31\n",
            "            Sports       0.81      0.51      0.63        43\n",
            "              Food       0.57      0.57      0.57        35\n",
            "               AMA       0.78      0.69      0.73        45\n",
            "\n",
            "          accuracy                           0.56       461\n",
            "         macro avg       0.61      0.56      0.56       461\n",
            "      weighted avg       0.62      0.56      0.57       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sOMwjqkGUID",
        "colab_type": "text"
      },
      "source": [
        "### 4.6 MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vezWFujsGYPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "dabdb864-c639-44ef-8732-248f52ba9767"
      },
      "source": [
        "mlp.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5119305856832972\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.70      0.62      0.66        34\n",
            "     Non-Political       0.40      0.31      0.35        39\n",
            "       Reddiquette       0.49      0.46      0.48        41\n",
            "         Scheduled       0.71      0.67      0.69        36\n",
            "       Photography       0.11      0.18      0.14        38\n",
            "Science/Technology       0.57      0.53      0.55        32\n",
            "          Politics       0.45      0.51      0.48        43\n",
            "  Business/Finance       0.62      0.64      0.63        44\n",
            "    Policy/Economy       0.60      0.29      0.39        31\n",
            "            Sports       0.64      0.63      0.64        43\n",
            "              Food       0.43      0.66      0.52        35\n",
            "               AMA       0.87      0.60      0.71        45\n",
            "\n",
            "          accuracy                           0.51       461\n",
            "         macro avg       0.55      0.51      0.52       461\n",
            "      weighted avg       0.55      0.51      0.52       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZrxi9BEHAfm",
        "colab_type": "text"
      },
      "source": [
        "## 3. Multivariate Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g-k5-6xHF_-",
        "colab_type": "text"
      },
      "source": [
        "### Combining title, comments and body\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsrv01RQGi4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X5_test = X_test['title'] + X_test['comm'] + X_test['body']\n",
        "X5_train = X_train['title'] + X_train['comm'] + X_train['body']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw_DfhcpJjj5",
        "colab_type": "text"
      },
      "source": [
        "### 1. Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vi6UUhbISKA",
        "colab_type": "code",
        "outputId": "3bb1506f-922e-41a6-a6f2-57c7bfc8c801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "nb.fit(X5_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6030368763557483\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.34      0.88      0.49        34\n",
            "     Non-Political       0.48      0.56      0.52        39\n",
            "       Reddiquette       0.50      0.78      0.61        41\n",
            "         Scheduled       0.75      0.75      0.75        36\n",
            "       Photography       1.00      0.16      0.27        38\n",
            "Science/Technology       0.84      0.81      0.83        32\n",
            "          Politics       0.51      0.74      0.60        43\n",
            "  Business/Finance       0.71      0.55      0.62        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.92      0.56      0.70        43\n",
            "              Food       0.76      0.63      0.69        35\n",
            "               AMA       0.89      0.73      0.80        45\n",
            "\n",
            "          accuracy                           0.60       461\n",
            "         macro avg       0.64      0.60      0.57       461\n",
            "      weighted avg       0.65      0.60      0.58       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otmlES8eJpBg",
        "colab_type": "text"
      },
      "source": [
        "### 2. SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43sTzWs1IjPn",
        "colab_type": "code",
        "outputId": "c02b1232-28c4-4642-d67b-7dd6e4482e3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "sgd1 = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
        "               ])\n",
        "\n",
        "sgd1.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = sgd1.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.7852494577006508\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.76      0.94      0.84        34\n",
            "     Non-Political       0.78      0.72      0.75        39\n",
            "       Reddiquette       0.74      0.76      0.75        41\n",
            "         Scheduled       0.78      0.86      0.82        36\n",
            "       Photography       0.74      0.68      0.71        38\n",
            "Science/Technology       0.83      0.94      0.88        32\n",
            "          Politics       0.74      0.74      0.74        43\n",
            "  Business/Finance       0.84      0.82      0.83        44\n",
            "    Policy/Economy       0.95      0.58      0.72        31\n",
            "            Sports       0.80      0.81      0.80        43\n",
            "              Food       0.68      0.74      0.71        35\n",
            "               AMA       0.86      0.82      0.84        45\n",
            "\n",
            "          accuracy                           0.79       461\n",
            "         macro avg       0.79      0.79      0.78       461\n",
            "      weighted avg       0.79      0.79      0.78       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvywgCkCJ0G1",
        "colab_type": "text"
      },
      "source": [
        "###3. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vepJ8fX2JwiC",
        "colab_type": "code",
        "outputId": "1088752e-35bc-4880-eb81-99fef7d6a68f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "logreg.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.7483731019522777\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.79      0.76      0.78        34\n",
            "     Non-Political       0.58      0.82      0.68        39\n",
            "       Reddiquette       0.76      0.68      0.72        41\n",
            "         Scheduled       0.79      0.86      0.83        36\n",
            "       Photography       0.69      0.63      0.66        38\n",
            "Science/Technology       0.88      0.88      0.88        32\n",
            "          Politics       0.71      0.67      0.69        43\n",
            "  Business/Finance       0.72      0.75      0.73        44\n",
            "    Policy/Economy       0.95      0.58      0.72        31\n",
            "            Sports       0.77      0.79      0.78        43\n",
            "              Food       0.65      0.74      0.69        35\n",
            "               AMA       0.90      0.80      0.85        45\n",
            "\n",
            "          accuracy                           0.75       461\n",
            "         macro avg       0.76      0.75      0.75       461\n",
            "      weighted avg       0.76      0.75      0.75       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuXlijt0L0qJ",
        "colab_type": "text"
      },
      "source": [
        "### 4. AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deUo3MmaKCM-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "125cd8c0-615c-4e33-f766-29824568fbda"
      },
      "source": [
        "ada.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5162689804772235\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.52      0.44      0.48        34\n",
            "     Non-Political       0.42      0.38      0.40        39\n",
            "       Reddiquette       0.82      0.68      0.75        41\n",
            "         Scheduled       0.39      0.53      0.45        36\n",
            "       Photography       0.50      0.37      0.42        38\n",
            "Science/Technology       0.84      0.66      0.74        32\n",
            "          Politics       0.47      0.42      0.44        43\n",
            "  Business/Finance       0.23      0.57      0.33        44\n",
            "    Policy/Economy       0.94      0.48      0.64        31\n",
            "            Sports       0.54      0.44      0.49        43\n",
            "              Food       0.79      0.74      0.76        35\n",
            "               AMA       0.79      0.51      0.62        45\n",
            "\n",
            "          accuracy                           0.52       461\n",
            "         macro avg       0.60      0.52      0.54       461\n",
            "      weighted avg       0.59      0.52      0.54       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtOp60h6L_z1",
        "colab_type": "text"
      },
      "source": [
        "### 5. Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4294zJcYL7np",
        "colab_type": "code",
        "outputId": "2f4b55c5-9020-488c-80b7-a53e8feea13e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "ranfor.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.8112798264642083\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.85      0.85      0.85        34\n",
            "     Non-Political       0.74      0.90      0.81        39\n",
            "       Reddiquette       0.78      0.76      0.77        41\n",
            "         Scheduled       0.84      0.86      0.85        36\n",
            "       Photography       0.72      0.76      0.74        38\n",
            "Science/Technology       0.78      0.88      0.82        32\n",
            "          Politics       0.79      0.77      0.78        43\n",
            "  Business/Finance       0.80      0.82      0.81        44\n",
            "    Policy/Economy       1.00      0.65      0.78        31\n",
            "            Sports       0.89      0.77      0.82        43\n",
            "              Food       0.68      0.80      0.74        35\n",
            "               AMA       0.98      0.91      0.94        45\n",
            "\n",
            "          accuracy                           0.81       461\n",
            "         macro avg       0.82      0.81      0.81       461\n",
            "      weighted avg       0.82      0.81      0.81       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CekS2NInMITb",
        "colab_type": "text"
      },
      "source": [
        "### 6. MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRH5v4yKMG-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "58720923-d182-4a17-a0bd-9cab1bf9b776"
      },
      "source": [
        "mlp.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6767895878524945\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.89      0.71      0.79        34\n",
            "     Non-Political       0.47      0.77      0.58        39\n",
            "       Reddiquette       0.78      0.61      0.68        41\n",
            "         Scheduled       0.78      0.81      0.79        36\n",
            "       Photography       0.49      0.66      0.56        38\n",
            "Science/Technology       0.74      0.81      0.78        32\n",
            "          Politics       0.60      0.67      0.64        43\n",
            "  Business/Finance       0.66      0.57      0.61        44\n",
            "    Policy/Economy       0.91      0.32      0.48        31\n",
            "            Sports       0.74      0.74      0.74        43\n",
            "              Food       0.64      0.60      0.62        35\n",
            "               AMA       0.86      0.80      0.83        45\n",
            "\n",
            "          accuracy                           0.68       461\n",
            "         macro avg       0.71      0.67      0.67       461\n",
            "      weighted avg       0.71      0.68      0.68       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbiLIBeoNCxw",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest performed the best with title, comments and body as features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QluvvuqSuG2",
        "colab_type": "text"
      },
      "source": [
        "### Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H40QavkdMhZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'final_model2.sav'\n",
        "pickle.dump(ranfor, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZWfzCEAVv_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}