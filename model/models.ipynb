{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX0YtJEL9OCZ",
        "colab_type": "code",
        "outputId": "a92d7128-1f01-471b-c091-a2b6590516eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!pip install pymongo\n",
        "\n",
        "import logging\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from numpy import random\n",
        "import gensim\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (3.9.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHVoh1KI8Nm2",
        "colab_type": "text"
      },
      "source": [
        "## Getting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxPVFxLX9WXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "client = MongoClient('mongodb://nitish:umeshpapa123@cluster0-shard-00-00-ifnda.mongodb.net:27017,cluster0-shard-00-01-ifnda.mongodb.net:27017,cluster0-shard-00-02-ifnda.mongodb.net:27017/test?ssl=true&replicaSet=Cluster0-shard-0&authSource=admin&retryWrites=true&w=majority')\n",
        "db = client.database\n",
        "collection = db.data_collection\n",
        "posts = db.posts\n",
        "data = posts.find_one()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLQa4xvs-OK3",
        "colab_type": "code",
        "outputId": "e21f6d68-65a1-4aa4-b728-b4b66b6e56fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "data = pd.DataFrame(data)\n",
        "plt.figure(figsize=(10,4))\n",
        "data.flair.value_counts().plot(kind='bar');\n",
        "flairs = [\"AskIndia\", \"Non-Political\", \"Reddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\", \"AMA\"]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAFVCAYAAAA35UGiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERFRkyRaERERETVJohURERFRk/8PLTj1V25JMEYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkgRsdxq-SY_",
        "colab_type": "code",
        "outputId": "564e1af8-3e1d-4535-85f4-ebcfd14267d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "source": [
        "data = data.drop(columns=\"_id\")\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flair</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>score</th>\n",
              "      <th>url</th>\n",
              "      <th>num_comm</th>\n",
              "      <th>created</th>\n",
              "      <th>id</th>\n",
              "      <th>author</th>\n",
              "      <th>comm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>Need feedback for Insurance Policy that I took...</td>\n",
              "      <td>**Re-posting here because of lack of activity ...</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/1s57oi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.386254e+09</td>\n",
              "      <td>1s57oi</td>\n",
              "      <td>dhavalcoholic</td>\n",
              "      <td>Dear Policy Holder(Dhavalcoholic),\\n \\nWe req...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>Somebody want to kill my full family what to do?</td>\n",
              "      <td>It's now 24hrs, But local police station is no...</td>\n",
              "      <td>92</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/b7pvwt...</td>\n",
              "      <td>24</td>\n",
              "      <td>1.554080e+09</td>\n",
              "      <td>b7pvwt</td>\n",
              "      <td>amitkumarthakur</td>\n",
              "      <td>Calm down.\\nGo to the SP office of your town,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>Ambassador of India takes back my newly issued...</td>\n",
              "      <td>Hello /AskIndia!  First time poster, long time...</td>\n",
              "      <td>13</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/bdfid1...</td>\n",
              "      <td>27</td>\n",
              "      <td>1.555361e+09</td>\n",
              "      <td>bdfid1</td>\n",
              "      <td>FrustratedOCIHopeful</td>\n",
              "      <td>Honestly, she and her supervisor behaved *exa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>Randians, what are you too afraid to ask?</td>\n",
              "      <td>r/TooAfraidToAsk India edition</td>\n",
              "      <td>16</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/cu1xn4...</td>\n",
              "      <td>22</td>\n",
              "      <td>1.566529e+09</td>\n",
              "      <td>cu1xn4</td>\n",
              "      <td>aloo_vs_bhaloo</td>\n",
              "      <td>How does Modi control his sex desires? Or if ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>[AskIndia] Cingari, Cengar or Tzengar?</td>\n",
              "      <td>Hello,\\n\\nI submitted this to /r/rAskIndia a w...</td>\n",
              "      <td>0</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/18ntue...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.361085e+09</td>\n",
              "      <td>18ntue</td>\n",
              "      <td>multubunu</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      flair  ...                                               comm\n",
              "0  AskIndia  ...   Dear Policy Holder(Dhavalcoholic),\\n \\nWe req...\n",
              "1  AskIndia  ...   Calm down.\\nGo to the SP office of your town,...\n",
              "2  AskIndia  ...   Honestly, she and her supervisor behaved *exa...\n",
              "3  AskIndia  ...   How does Modi control his sex desires? Or if ...\n",
              "4  AskIndia  ...                                                   \n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5klpYDR7gqC",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-QfbU0y7jlP",
        "colab_type": "code",
        "outputId": "733e2c01-9841-4672-edbf-89b61fa4662a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    return text\n",
        "  \n",
        "def todate(created):\n",
        "    return dt.datetime.fromtimestamp(created)\n",
        "  \n",
        "try:\n",
        "  created = data[\"created\"].apply(todate)\n",
        "  data = data.assign(created = created)\n",
        "except:\n",
        "  print(\"already timestamp\")\n",
        "\n",
        "def tostr(value):\n",
        "    return str(value)\n",
        "  \n",
        "data['title'] = data['title'].apply(tostr)\n",
        "data['title'] = data['title'].apply(clean_text)\n",
        "data['body'] = data['body'].apply(tostr)\n",
        "data['body'] = data['body'].apply(clean_text)\n",
        "data['comm'] = data['comm'].apply(tostr)\n",
        "data['comm'] = data['comm'].apply(clean_text)\n",
        "data['url'] = data['url'].apply(tostr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://youtu.be/kBvIqVr__C0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n30eEh41Gb8y",
        "colab_type": "code",
        "outputId": "db3cda6c-6aac-4bb0-f9e9-b33d98ffb4ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "source": [
        "data.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flair</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>score</th>\n",
              "      <th>url</th>\n",
              "      <th>num_comm</th>\n",
              "      <th>created</th>\n",
              "      <th>id</th>\n",
              "      <th>author</th>\n",
              "      <th>comm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2296</th>\n",
              "      <td>AMA</td>\n",
              "      <td>r india met spent time celebrity actors anyone...</td>\n",
              "      <td></td>\n",
              "      <td>33</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/1u5caw...</td>\n",
              "      <td>168</td>\n",
              "      <td>2014-01-01 15:40:35</td>\n",
              "      <td>1u5caw</td>\n",
              "      <td>varuval</td>\n",
              "      <td>true storyi peed standing next ratan tata los ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2297</th>\n",
              "      <td>AMA</td>\n",
              "      <td>upcoming ama rocky mayur monday 4th august 120...</td>\n",
              "      <td>rocky singh mayur sharma childhood friends tog...</td>\n",
              "      <td>83</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/2cesw5...</td>\n",
              "      <td>59</td>\n",
              "      <td>2014-08-02 16:28:37</td>\n",
              "      <td>2cesw5</td>\n",
              "      <td>rahulthewall</td>\n",
              "      <td>welcome guys http wwwredditcom r india comment...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2298</th>\n",
              "      <td>AMA</td>\n",
              "      <td>friend completed cycling 6200 kms kashmir kany...</td>\n",
              "      <td></td>\n",
              "      <td>455</td>\n",
              "      <td>http://imgur.com/fv9DA</td>\n",
              "      <td>62</td>\n",
              "      <td>2013-01-06 20:38:16</td>\n",
              "      <td>1624gc</td>\n",
              "      <td>petty86</td>\n",
              "      <td>great achievement indeed convince ama listed e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2299</th>\n",
              "      <td>AMA</td>\n",
              "      <td>priyanka chopras reaction ama</td>\n",
              "      <td></td>\n",
              "      <td>94</td>\n",
              "      <td>http://gfycat.com/InsistentFlamboyantInganue</td>\n",
              "      <td>59</td>\n",
              "      <td>2014-07-03 04:39:38</td>\n",
              "      <td>29ojfi</td>\n",
              "      <td>DesiGif</td>\n",
              "      <td>one new profiles pr team created asked last ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2300</th>\n",
              "      <td>AMA</td>\n",
              "      <td>hey reddit im anoop bhat draw stuff pen ink ba...</td>\n",
              "      <td>hi im anoop architect freelance illustrator ba...</td>\n",
              "      <td>147</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/84lr68...</td>\n",
              "      <td>103</td>\n",
              "      <td>2018-03-15 19:32:47</td>\n",
              "      <td>84lr68</td>\n",
              "      <td>scourgwreck</td>\n",
              "      <td>hi anoopdo sell posters online ship outside in...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     flair  ...                                               comm\n",
              "2296   AMA  ...  true storyi peed standing next ratan tata los ...\n",
              "2297   AMA  ...  welcome guys http wwwredditcom r india comment...\n",
              "2298   AMA  ...  great achievement indeed convince ama listed e...\n",
              "2299   AMA  ...  one new profiles pr team created asked last ti...\n",
              "2300   AMA  ...  hi anoopdo sell posters online ship outside in...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SosgjCUCOP0a",
        "colab_type": "text"
      },
      "source": [
        "## 1. Feature #1 : Title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy0VsCtWQRAX",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl51oLlCOSbi",
        "colab_type": "code",
        "outputId": "7230a919-e3bb-4b40-bf1e-5c540d0f106d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Only taking title, body, url, comments as features as they have the most\n",
        "# significant amount of natural language related to the flair\n",
        "\n",
        "X = data[['title', 'body', 'url', 'comm']]\n",
        "y = data['flair']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "\n",
        "X1_train = X_train['title']\n",
        "X1_test = X_test['title']\n",
        "\n",
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "nb.fit(X1_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6268980477223427\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.61      0.65      0.63        34\n",
            "     Non-Political       0.53      0.85      0.65        39\n",
            "       Reddiquette       0.59      0.39      0.47        41\n",
            "         Scheduled       0.69      0.75      0.72        36\n",
            "       Photography       0.77      0.95      0.85        38\n",
            "Science/Technology       0.51      0.75      0.61        32\n",
            "          Politics       0.53      0.58      0.56        43\n",
            "  Business/Finance       0.59      0.45      0.51        44\n",
            "    Policy/Economy       1.00      0.16      0.28        31\n",
            "            Sports       0.68      0.60      0.64        43\n",
            "              Food       0.58      0.60      0.59        35\n",
            "               AMA       0.79      0.76      0.77        45\n",
            "\n",
            "          accuracy                           0.63       461\n",
            "         macro avg       0.66      0.62      0.61       461\n",
            "      weighted avg       0.65      0.63      0.61       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uRe9Im9QXGp",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 SGD/LinearSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqg2PSjaPA6C",
        "colab_type": "code",
        "outputId": "87b3b93f-0ecc-4209-efea-bc0a9c8e2ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
        "               ])\n",
        "sgd.fit(X1_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = sgd.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6919739696312365\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.65      0.71      0.68        34\n",
            "     Non-Political       0.78      0.90      0.83        39\n",
            "       Reddiquette       0.59      0.41      0.49        41\n",
            "         Scheduled       0.68      0.78      0.73        36\n",
            "       Photography       0.84      1.00      0.92        38\n",
            "Science/Technology       0.75      0.75      0.75        32\n",
            "          Politics       0.53      0.53      0.53        43\n",
            "  Business/Finance       0.65      0.50      0.56        44\n",
            "    Policy/Economy       0.76      0.61      0.68        31\n",
            "            Sports       0.70      0.72      0.71        43\n",
            "              Food       0.61      0.57      0.59        35\n",
            "               AMA       0.72      0.84      0.78        45\n",
            "\n",
            "          accuracy                           0.69       461\n",
            "         macro avg       0.69      0.69      0.69       461\n",
            "      weighted avg       0.69      0.69      0.68       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqOzt5g3Q156",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u5sQRStQmhA",
        "colab_type": "code",
        "outputId": "315a28af-ca94-466e-915c-57f15e6fd716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
        "               ])\n",
        "logreg.fit(X1_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6963123644251626\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.70      0.76      0.73        34\n",
            "     Non-Political       0.83      0.90      0.86        39\n",
            "       Reddiquette       0.56      0.46      0.51        41\n",
            "         Scheduled       0.70      0.78      0.74        36\n",
            "       Photography       0.93      0.97      0.95        38\n",
            "Science/Technology       0.70      0.72      0.71        32\n",
            "          Politics       0.62      0.60      0.61        43\n",
            "  Business/Finance       0.59      0.45      0.51        44\n",
            "    Policy/Economy       0.87      0.65      0.74        31\n",
            "            Sports       0.66      0.67      0.67        43\n",
            "              Food       0.62      0.57      0.60        35\n",
            "               AMA       0.63      0.84      0.72        45\n",
            "\n",
            "          accuracy                           0.70       461\n",
            "         macro avg       0.70      0.70      0.70       461\n",
            "      weighted avg       0.69      0.70      0.69       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkrWHgCDSjWj",
        "colab_type": "text"
      },
      "source": [
        "### 1.4 AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-7GjUNwSlyA",
        "colab_type": "code",
        "outputId": "b12f8867-94d0-4c72-89c0-c8927f79d473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', AdaBoostClassifier(n_estimators = 500, learning_rate=0.9)),\n",
        "               ])\n",
        "ada.fit(X1_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.4078091106290672\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.95      0.56      0.70        34\n",
            "     Non-Political       0.92      0.87      0.89        39\n",
            "       Reddiquette       0.13      0.93      0.23        41\n",
            "         Scheduled       0.88      0.58      0.70        36\n",
            "       Photography       1.00      0.03      0.05        38\n",
            "Science/Technology       1.00      0.56      0.72        32\n",
            "          Politics       0.00      0.00      0.00        43\n",
            "  Business/Finance       0.00      0.00      0.00        44\n",
            "    Policy/Economy       0.86      0.58      0.69        31\n",
            "            Sports       1.00      0.40      0.57        43\n",
            "              Food       0.90      0.26      0.40        35\n",
            "               AMA       0.93      0.29      0.44        45\n",
            "\n",
            "          accuracy                           0.41       461\n",
            "         macro avg       0.71      0.42      0.45       461\n",
            "      weighted avg       0.69      0.41      0.43       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2hBfrV2WF9b",
        "colab_type": "text"
      },
      "source": [
        "### 1.5 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax_-PNk1WH9_",
        "colab_type": "code",
        "outputId": "2086a6fe-2911-4502-fcff-672292453624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "  \n",
        "ranfor = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', RandomForestClassifier(n_estimators = 500, random_state = 42)),\n",
        "                 ])\n",
        "ranfor.fit(X1_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6550976138828634\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.64      0.62      0.63        34\n",
            "     Non-Political       0.88      0.90      0.89        39\n",
            "       Reddiquette       0.47      0.51      0.49        41\n",
            "         Scheduled       0.71      0.81      0.75        36\n",
            "       Photography       0.93      0.97      0.95        38\n",
            "Science/Technology       0.65      0.69      0.67        32\n",
            "          Politics       0.45      0.56      0.50        43\n",
            "  Business/Finance       0.54      0.45      0.49        44\n",
            "    Policy/Economy       0.95      0.58      0.72        31\n",
            "            Sports       0.74      0.53      0.62        43\n",
            "              Food       0.43      0.51      0.47        35\n",
            "               AMA       0.74      0.76      0.75        45\n",
            "\n",
            "          accuracy                           0.66       461\n",
            "         macro avg       0.68      0.66      0.66       461\n",
            "      weighted avg       0.67      0.66      0.66       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18Lqp9jGX_BB",
        "colab_type": "text"
      },
      "source": [
        "### 1.6 MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plePunVAYDrf",
        "colab_type": "code",
        "outputId": "71713508-56ff-4a1c-9373-72499090a6f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "  \n",
        "mlp = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', MLPClassifier(hidden_layer_sizes=(35,35,35), alpha=0.1, random_state=42, max_iter=200)),\n",
        "                 ])\n",
        "  \n",
        "mlp.fit(X1_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X1_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.631236442516269\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.51      0.65      0.57        34\n",
            "     Non-Political       0.82      0.85      0.84        39\n",
            "       Reddiquette       0.58      0.37      0.45        41\n",
            "         Scheduled       0.64      0.69      0.67        36\n",
            "       Photography       0.95      0.92      0.93        38\n",
            "Science/Technology       0.72      0.66      0.69        32\n",
            "          Politics       0.38      0.65      0.48        43\n",
            "  Business/Finance       0.39      0.48      0.43        44\n",
            "    Policy/Economy       0.88      0.45      0.60        31\n",
            "            Sports       0.82      0.65      0.73        43\n",
            "              Food       0.57      0.49      0.52        35\n",
            "               AMA       0.82      0.71      0.76        45\n",
            "\n",
            "          accuracy                           0.63       461\n",
            "         macro avg       0.67      0.63      0.64       461\n",
            "      weighted avg       0.67      0.63      0.64       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmEecWPMcXlo",
        "colab_type": "text"
      },
      "source": [
        "## 2. Feature #2 : Body"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBdw0kFNchE5",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxP91vMHagKQ",
        "colab_type": "code",
        "outputId": "6cebbe86-52cb-4293-af89-3e758f9755bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "X2_train = X_train['body']\n",
        "X2_test = X_test['body']\n",
        "\n",
        "nb.fit(X2_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.23644251626898047\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.67      0.29      0.41        34\n",
            "     Non-Political       0.34      0.54      0.42        39\n",
            "       Reddiquette       0.23      0.68      0.34        41\n",
            "         Scheduled       0.33      0.03      0.05        36\n",
            "       Photography       0.00      0.00      0.00        38\n",
            "Science/Technology       0.12      0.84      0.21        32\n",
            "          Politics       1.00      0.02      0.05        43\n",
            "  Business/Finance       0.00      0.00      0.00        44\n",
            "    Policy/Economy       1.00      0.16      0.28        31\n",
            "            Sports       0.50      0.07      0.12        43\n",
            "              Food       0.71      0.29      0.41        35\n",
            "               AMA       0.60      0.07      0.12        45\n",
            "\n",
            "          accuracy                           0.24       461\n",
            "         macro avg       0.46      0.25      0.20       461\n",
            "      weighted avg       0.45      0.24      0.19       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5pah0AT8Xzq",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 SGD/LinearSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwlavI2k8OHB",
        "colab_type": "code",
        "outputId": "9ecf08c1-6cea-467e-8d34-b6d4aee3d21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "sgd.fit(X2_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = sgd.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.3665943600867679\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.60      0.44      0.51        34\n",
            "     Non-Political       0.45      0.46      0.46        39\n",
            "       Reddiquette       0.49      0.56      0.52        41\n",
            "         Scheduled       0.41      0.19      0.26        36\n",
            "       Photography       0.25      0.03      0.05        38\n",
            "Science/Technology       0.47      0.28      0.35        32\n",
            "          Politics       0.50      0.14      0.22        43\n",
            "  Business/Finance       0.17      0.82      0.28        44\n",
            "    Policy/Economy       0.79      0.61      0.69        31\n",
            "            Sports       0.55      0.14      0.22        43\n",
            "              Food       0.55      0.46      0.50        35\n",
            "               AMA       0.72      0.29      0.41        45\n",
            "\n",
            "          accuracy                           0.37       461\n",
            "         macro avg       0.50      0.37      0.37       461\n",
            "      weighted avg       0.49      0.37      0.36       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ck3492B9VaC",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndnqdtaz9Fq3",
        "colab_type": "code",
        "outputId": "1777494a-5ee1-46ae-e2cc-9442e8e7fa39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "logreg.fit(X2_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.3362255965292842\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.52      0.41      0.46        34\n",
            "     Non-Political       0.37      0.49      0.42        39\n",
            "       Reddiquette       0.58      0.51      0.55        41\n",
            "         Scheduled       0.50      0.19      0.28        36\n",
            "       Photography       0.08      0.03      0.04        38\n",
            "Science/Technology       0.45      0.28      0.35        32\n",
            "          Politics       0.38      0.12      0.18        43\n",
            "  Business/Finance       0.16      0.82      0.27        44\n",
            "    Policy/Economy       0.84      0.52      0.64        31\n",
            "            Sports       0.60      0.14      0.23        43\n",
            "              Food       0.47      0.40      0.43        35\n",
            "               AMA       0.70      0.16      0.25        45\n",
            "\n",
            "          accuracy                           0.34       461\n",
            "         macro avg       0.47      0.34      0.34       461\n",
            "      weighted avg       0.47      0.34      0.33       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1p8DH1n9oFy",
        "colab_type": "text"
      },
      "source": [
        "### 2.4 AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfauWsRe9tBM",
        "colab_type": "code",
        "outputId": "634d6982-a1bf-4b12-c9bf-58606251f8ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "ada.fit(X2_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.24295010845986983\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.30      0.35      0.32        34\n",
            "     Non-Political       0.16      0.26      0.20        39\n",
            "       Reddiquette       0.74      0.34      0.47        41\n",
            "         Scheduled       0.46      0.17      0.24        36\n",
            "       Photography       0.11      0.11      0.11        38\n",
            "Science/Technology       0.54      0.22      0.31        32\n",
            "          Politics       0.50      0.14      0.22        43\n",
            "  Business/Finance       0.16      0.80      0.26        44\n",
            "    Policy/Economy       0.62      0.16      0.26        31\n",
            "            Sports       0.29      0.05      0.08        43\n",
            "              Food       0.56      0.14      0.23        35\n",
            "               AMA       0.33      0.13      0.19        45\n",
            "\n",
            "          accuracy                           0.24       461\n",
            "         macro avg       0.40      0.24      0.24       461\n",
            "      weighted avg       0.39      0.24      0.24       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzsBh189-NG_",
        "colab_type": "text"
      },
      "source": [
        "### 2.5 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9RXz2Oz95O6",
        "colab_type": "code",
        "outputId": "f2300b1c-7e4d-4118-ff03-7e90e30a8498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "ranfor.fit(X2_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-892a6187e46e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mranfor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mranfor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zh_y9Rm-ewa",
        "colab_type": "text"
      },
      "source": [
        "### 2.6 MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xhYXP1E-WM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp.fit(X2_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X2_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3erY2S1Y-ygW",
        "colab_type": "text"
      },
      "source": [
        "## 3. Feature #3 : Url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hHfBCkK_VNE",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knVuhJuC-rX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X3_train = X_train['url']\n",
        "X3_test = X_test['url']\n",
        "\n",
        "nb.fit(X3_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_IJImFdAoqD",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 SGD/LinearSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6pGgYU4_a4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = sgd.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzyeSRNNA0CL",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfDLbb_yAyVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAjzohG0Bjes",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-NdBJwGBAg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ada.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYN9e6qNBsnI",
        "colab_type": "text"
      },
      "source": [
        "### 3.5 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nG2KWRFBp34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ranfor.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9LJgQPdCPgL",
        "colab_type": "text"
      },
      "source": [
        "### 3.6 MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTT2p78QBxzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp.fit(X3_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X3_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NP9Lw2GDOAc",
        "colab_type": "text"
      },
      "source": [
        "## 4. Feature #4 : Comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVi6tOtmDREO",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQg-kBb7CZUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X4_train = X_train['comm']\n",
        "X4_test = X_test['comm']\n",
        "\n",
        "nb.fit(X4_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fffogbRCEgsD",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 SGD/LinearSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jext-7jaD75J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = sgd.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SfAGIxzFBJu",
        "colab_type": "text"
      },
      "source": [
        "### 4.3 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd_5NlghEr7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XMJYS1oFwQj",
        "colab_type": "text"
      },
      "source": [
        "### 4.4 AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJrGg56mFF-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ada.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y0_MMcrF231",
        "colab_type": "text"
      },
      "source": [
        "### 4.5 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF77AY9qF1Ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ranfor.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sOMwjqkGUID",
        "colab_type": "text"
      },
      "source": [
        "### 4.6 MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vezWFujsGYPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp.fit(X4_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X4_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZrxi9BEHAfm",
        "colab_type": "text"
      },
      "source": [
        "## 3. Multivariate Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g-k5-6xHF_-",
        "colab_type": "text"
      },
      "source": [
        "### Combining title, comments and url\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsrv01RQGi4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X5_test = X_test['title'] + X_test['comm'] + X_test['url']\n",
        "X5_train = X_train['title'] + X_train['comm'] + X_train['url']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw_DfhcpJjj5",
        "colab_type": "text"
      },
      "source": [
        "### 1. Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vi6UUhbISKA",
        "colab_type": "code",
        "outputId": "c3798943-7336-4e3e-a146-9726d75e51e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "nb.fit(X5_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5856832971800434\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.28      0.88      0.43        34\n",
            "     Non-Political       0.51      0.54      0.53        39\n",
            "       Reddiquette       0.61      0.34      0.44        41\n",
            "         Scheduled       0.72      0.81      0.76        36\n",
            "       Photography       0.90      0.24      0.38        38\n",
            "Science/Technology       0.81      0.81      0.81        32\n",
            "          Politics       0.47      0.81      0.59        43\n",
            "  Business/Finance       0.67      0.66      0.67        44\n",
            "    Policy/Economy       0.00      0.00      0.00        31\n",
            "            Sports       0.77      0.56      0.65        43\n",
            "              Food       0.86      0.51      0.64        35\n",
            "               AMA       0.92      0.78      0.84        45\n",
            "\n",
            "          accuracy                           0.59       461\n",
            "         macro avg       0.63      0.58      0.56       461\n",
            "      weighted avg       0.64      0.59      0.57       461\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otmlES8eJpBg",
        "colab_type": "text"
      },
      "source": [
        "### 2. SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk8HWqF7M-F8",
        "colab_type": "text"
      },
      "source": [
        "#### Best Performer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43sTzWs1IjPn",
        "colab_type": "code",
        "outputId": "8bd8e2da-3770-43c3-e262-1a9d9267871f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "sgd1 = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
        "               ])\n",
        "\n",
        "sgd1.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = sgd1.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.7440347071583514\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.74      0.82      0.78        34\n",
            "     Non-Political       0.72      0.74      0.73        39\n",
            "       Reddiquette       0.65      0.54      0.59        41\n",
            "         Scheduled       0.74      0.89      0.81        36\n",
            "       Photography       0.81      0.66      0.72        38\n",
            "Science/Technology       0.76      0.88      0.81        32\n",
            "          Politics       0.62      0.72      0.67        43\n",
            "  Business/Finance       0.79      0.77      0.78        44\n",
            "    Policy/Economy       0.85      0.55      0.67        31\n",
            "            Sports       0.80      0.81      0.80        43\n",
            "              Food       0.65      0.69      0.67        35\n",
            "               AMA       0.86      0.84      0.85        45\n",
            "\n",
            "          accuracy                           0.74       461\n",
            "         macro avg       0.75      0.74      0.74       461\n",
            "      weighted avg       0.75      0.74      0.74       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvywgCkCJ0G1",
        "colab_type": "text"
      },
      "source": [
        "###3. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vepJ8fX2JwiC",
        "colab_type": "code",
        "outputId": "96313de7-4141-4ee1-f62b-09210afabe70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "logreg.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.7331887201735358\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.83      0.71      0.76        34\n",
            "     Non-Political       0.60      0.85      0.70        39\n",
            "       Reddiquette       0.60      0.61      0.60        41\n",
            "         Scheduled       0.77      0.83      0.80        36\n",
            "       Photography       0.73      0.63      0.68        38\n",
            "Science/Technology       0.81      0.81      0.81        32\n",
            "          Politics       0.63      0.67      0.65        43\n",
            "  Business/Finance       0.75      0.75      0.75        44\n",
            "    Policy/Economy       0.83      0.61      0.70        31\n",
            "            Sports       0.84      0.84      0.84        43\n",
            "              Food       0.65      0.69      0.67        35\n",
            "               AMA       0.92      0.78      0.84        45\n",
            "\n",
            "          accuracy                           0.73       461\n",
            "         macro avg       0.75      0.73      0.73       461\n",
            "      weighted avg       0.74      0.73      0.73       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuXlijt0L0qJ",
        "colab_type": "text"
      },
      "source": [
        "### 4. AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deUo3MmaKCM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ada.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtOp60h6L_z1",
        "colab_type": "text"
      },
      "source": [
        "### 5. Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4294zJcYL7np",
        "colab_type": "code",
        "outputId": "1ac10d53-b1f7-491d-dff2-552584685834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "ranfor.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = ranfor.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.735357917570499\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.70      0.76      0.73        34\n",
            "     Non-Political       0.69      0.87      0.77        39\n",
            "       Reddiquette       0.64      0.51      0.57        41\n",
            "         Scheduled       0.79      0.86      0.83        36\n",
            "       Photography       0.68      0.71      0.69        38\n",
            "Science/Technology       0.74      0.88      0.80        32\n",
            "          Politics       0.66      0.63      0.64        43\n",
            "  Business/Finance       0.75      0.82      0.78        44\n",
            "    Policy/Economy       1.00      0.45      0.62        31\n",
            "            Sports       0.86      0.84      0.85        43\n",
            "              Food       0.53      0.60      0.56        35\n",
            "               AMA       0.95      0.84      0.89        45\n",
            "\n",
            "          accuracy                           0.74       461\n",
            "         macro avg       0.75      0.73      0.73       461\n",
            "      weighted avg       0.75      0.74      0.73       461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CekS2NInMITb",
        "colab_type": "text"
      },
      "source": [
        "### 6. MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRH5v4yKMG-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp.fit(X5_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X5_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbiLIBeoNCxw",
        "colab_type": "text"
      },
      "source": [
        "### SGD/LinearSVM performed the best with title, comments and url as features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QluvvuqSuG2",
        "colab_type": "text"
      },
      "source": [
        "### Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H40QavkdMhZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'final_model1.sav'\n",
        "pickle.dump(sgd1, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZWfzCEAVv_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}